{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:52.987065Z",
     "start_time": "2024-05-04T09:26:52.009378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1760, 12), (220, 12), (220, 12))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Crop_Dataset.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, train_size=0.8, random_state=10)\n",
    "validation_data, test_data = train_test_split(test_data, train_size=0.5, random_state=10)\n",
    "\n",
    "train_data.shape, test_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(data['Label_Encoded'].unique())\n",
    "n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:52.993058Z",
     "start_time": "2024-05-04T09:26:52.988132Z"
    }
   },
   "id": "134db0c50579d075"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"mps\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:34:18.340051Z",
     "start_time": "2024-05-04T09:34:18.315086Z"
    }
   },
   "id": "25c98d5511cd1168"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 5, 8.825674745, 14.25803981, 3.504752314, 20.21126747, 17, 247.6131816, 3.054532525] [140, 145, 205, 43.67549305, 99.98187601, 9.93509073, 298.5601175, 385, 4073.159566, 5.702315124]\n"
     ]
    }
   ],
   "source": [
    "# manual normalization\n",
    "\n",
    "min_values = []\n",
    "max_values = []\n",
    "\n",
    "for i in range(10):\n",
    "    min_values.append(data.iloc[:, i].min())\n",
    "    max_values.append(data.iloc[:, i].max())\n",
    "    \n",
    "print(min_values, max_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.002761Z",
     "start_time": "2024-05-04T09:26:54.000214Z"
    }
   },
   "id": "fd3a18a1d572a76a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.inputs = data.iloc[:, 0:-2].values.astype('float32')\n",
    "        \n",
    "        # for i in range(self.inputs.shape[1]):\n",
    "        #     self.inputs[:, i] = normalize(torch.tensor(self.inputs[:, i].reshape(-1, 1)), dim=0).reshape(-1)\n",
    "        \n",
    "        for i in range(self.inputs.shape[1]):\n",
    "            max_val = max_values[i]\n",
    "            min_val = min_values[i]\n",
    "            self.inputs[:, i] = (self.inputs[:, i] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        self.outputs = data.iloc[:, -1].values.astype('int')\n",
    "        \n",
    "        self.inputs = torch.tensor(self.inputs, device=device)\n",
    "        self.outputs = torch.tensor(self.outputs, device=device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.008333Z",
     "start_time": "2024-05-04T09:26:54.003855Z"
    }
   },
   "id": "6f491ad7458c9537"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(CustomDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(CustomDataset(test_data), batch_size=batch_size, shuffle=True)\n",
    "validation_data_loader = torch.utils.data.DataLoader(CustomDataset(validation_data), batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.097275Z",
     "start_time": "2024-05-04T09:26:54.008084Z"
    }
   },
   "id": "97345e2e0fba23c6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([128, 10])\n",
      "Shape of y:  torch.Size([128]) torch.int64\n",
      "Sample X:  tensor([0.2786, 0.2286, 0.0500, 0.5788, 0.8111, 0.5158, 0.1424, 0.2011, 0.5704,\n",
      "        0.3980], device='mps:0')\n",
      "Sample y:  tensor(6, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# print shapes and samples from the dataset\n",
    "for X, y in train_data_loader:\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    print(\"Sample X: \", X[0])\n",
    "    print(\"Sample y: \", y[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.325131Z",
     "start_time": "2024-05-04T09:26:54.073682Z"
    }
   },
   "id": "5545db8d69fbc4fa"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 22),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.325307Z",
     "start_time": "2024-05-04T09:26:54.322348Z"
    }
   },
   "id": "c232c3144a1df0d6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=22, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.331737Z",
     "start_time": "2024-05-04T09:26:54.326415Z"
    }
   },
   "id": "c272fb94daa41e97"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# testing predictions\n",
    "\n",
    "_X = torch.rand(1, 10, device=device)\n",
    "logits = model(_X)\n",
    "predicted_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = predicted_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.395946Z",
     "start_time": "2024-05-04T09:26:54.333712Z"
    }
   },
   "id": "100378c7ad3a6a73"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:54.403099Z",
     "start_time": "2024-05-04T09:26:54.397221Z"
    }
   },
   "id": "4993b936e24ca0f3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlakshith\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/lakshithnishshanke/Developer/Intellihack/Intellihack_Rizzmoid_1/wandb/run-20240504_145655-qud2tukl</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='http://localhost:8080/lakshith/Intellihack_1/runs/qud2tukl' target=\"_blank\">star-republic-24</a></strong> to <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='http://localhost:8080/lakshith/Intellihack_1/runs/qud2tukl' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1/runs/qud2tukl</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='http://localhost:8080/lakshith/Intellihack_1/runs/qud2tukl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x14041a3a0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "configs = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"ANN\",\n",
    "    \"dataset\": \"Crop\",\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Intellihack_1\",\n",
    "    config=configs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:57.738890Z",
     "start_time": "2024-05-04T09:26:54.399781Z"
    }
   },
   "id": "3f08bf8faaddb863"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_loop(dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, current = loss.item(), batch * batch_size + len(X)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Loss\": loss\n",
    "        })\n",
    "        print(f\"\\rloss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:57.744030Z",
     "start_time": "2024-05-04T09:26:57.739870Z"
    }
   },
   "id": "263db61f89b14c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def test_loop(dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    wandb.log({\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"Test Accuracy\": correct\n",
    "    })\n",
    "    \n",
    "    print(\"Test: \\nAccuracy: \", correct, \"\\nAvg loss: \", test_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:57.764334Z",
     "start_time": "2024-05-04T09:26:57.745189Z"
    }
   },
   "id": "7a025d958375368f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:26:57.765401Z",
     "start_time": "2024-05-04T09:26:57.752466Z"
    }
   },
   "id": "919104987103baeb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.089881  [  928/ 1760]Test: \n",
      "Accuracy:  0.03636363636363636 \n",
      "Avg loss:  3.092055082321167\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.088497  [  928/ 1760]Test: \n",
      "Accuracy:  0.06363636363636363 \n",
      "Avg loss:  3.0833152532577515\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.063095  [  928/ 1760]Test: \n",
      "Accuracy:  0.07727272727272727 \n",
      "Avg loss:  3.076580047607422\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.063967  [  928/ 1760]Test: \n",
      "Accuracy:  0.10909090909090909 \n",
      "Avg loss:  3.0689709186553955\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.060498  [  928/ 1760]Test: \n",
      "Accuracy:  0.12727272727272726 \n",
      "Avg loss:  3.0622379779815674\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.059889  [  928/ 1760]Test: \n",
      "Accuracy:  0.17727272727272728 \n",
      "Avg loss:  3.054377555847168\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.042124  [  928/ 1760]Test: \n",
      "Accuracy:  0.20909090909090908 \n",
      "Avg loss:  3.047690987586975\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.042818  [  928/ 1760]Test: \n",
      "Accuracy:  0.21818181818181817 \n",
      "Avg loss:  3.0418248176574707\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.030354  [  928/ 1760]Test: \n",
      "Accuracy:  0.20454545454545456 \n",
      "Avg loss:  3.0345295667648315\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.025706  [  928/ 1760]Test: \n",
      "Accuracy:  0.19545454545454546 \n",
      "Avg loss:  3.028107762336731\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.018536  [  928/ 1760]Test: \n",
      "Accuracy:  0.18636363636363637 \n",
      "Avg loss:  3.021594524383545\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.999371  [  928/ 1760]Test: \n",
      "Accuracy:  0.2 \n",
      "Avg loss:  3.0129367113113403\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.008797  [  928/ 1760]Test: \n",
      "Accuracy:  0.20454545454545456 \n",
      "Avg loss:  3.006727933883667\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.981833  [  928/ 1760]Test: \n",
      "Accuracy:  0.2318181818181818 \n",
      "Avg loss:  2.9995287656784058\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.986374  [  928/ 1760]Test: \n",
      "Accuracy:  0.22727272727272727 \n",
      "Avg loss:  2.9931384325027466\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.962863  [  928/ 1760]Test: \n",
      "Accuracy:  0.25 \n",
      "Avg loss:  2.9854291677474976\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.976038  [  928/ 1760]Test: \n",
      "Accuracy:  0.2772727272727273 \n",
      "Avg loss:  2.977500796318054\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.963065  [  928/ 1760]Test: \n",
      "Accuracy:  0.2863636363636364 \n",
      "Avg loss:  2.9684795141220093\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.957786  [  928/ 1760]Test: \n",
      "Accuracy:  0.2909090909090909 \n",
      "Avg loss:  2.9622485637664795\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.922384  [  928/ 1760]Test: \n",
      "Accuracy:  0.3 \n",
      "Avg loss:  2.953472137451172\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.958776  [  928/ 1760]Test: \n",
      "Accuracy:  0.3090909090909091 \n",
      "Avg loss:  2.9484986066818237\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.951538  [  928/ 1760]Test: \n",
      "Accuracy:  0.31363636363636366 \n",
      "Avg loss:  2.937225818634033\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.918705  [  928/ 1760]Test: \n",
      "Accuracy:  0.3090909090909091 \n",
      "Avg loss:  2.926680088043213\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.891785  [  928/ 1760]Test: \n",
      "Accuracy:  0.3181818181818182 \n",
      "Avg loss:  2.9201654195785522\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.916408  [  928/ 1760]Test: \n",
      "Accuracy:  0.32727272727272727 \n",
      "Avg loss:  2.9068208932876587\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.915271  [  928/ 1760]Test: \n",
      "Accuracy:  0.32272727272727275 \n",
      "Avg loss:  2.896766424179077\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.830477  [  928/ 1760]Test: \n",
      "Accuracy:  0.3181818181818182 \n",
      "Avg loss:  2.8863736391067505\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.897438  [  928/ 1760]Test: \n",
      "Accuracy:  0.3181818181818182 \n",
      "Avg loss:  2.8745731115341187\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.841525  [  928/ 1760]Test: \n",
      "Accuracy:  0.31363636363636366 \n",
      "Avg loss:  2.863285779953003\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.833617  [  928/ 1760]Test: \n",
      "Accuracy:  0.31363636363636366 \n",
      "Avg loss:  2.853228211402893\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.857718  [  928/ 1760]Test: \n",
      "Accuracy:  0.3181818181818182 \n",
      "Avg loss:  2.842046022415161\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.825371  [  928/ 1760]Test: \n",
      "Accuracy:  0.32272727272727275 \n",
      "Avg loss:  2.8304985761642456\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.780926  [  928/ 1760]Test: \n",
      "Accuracy:  0.32272727272727275 \n",
      "Avg loss:  2.816778063774109\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.809912  [  928/ 1760]Test: \n",
      "Accuracy:  0.32727272727272727 \n",
      "Avg loss:  2.803748846054077\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.773852  [  928/ 1760]Test: \n",
      "Accuracy:  0.33636363636363636 \n",
      "Avg loss:  2.7876060009002686\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.762942  [  928/ 1760]Test: \n",
      "Accuracy:  0.33181818181818185 \n",
      "Avg loss:  2.7768150568008423\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.748615  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.7568191289901733\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.748204  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.746638536453247\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.701271  [  928/ 1760]Test: \n",
      "Accuracy:  0.36363636363636365 \n",
      "Avg loss:  2.734349489212036\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.742434  [  928/ 1760]Test: \n",
      "Accuracy:  0.37727272727272726 \n",
      "Avg loss:  2.7186073064804077\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.673411  [  928/ 1760]Test: \n",
      "Accuracy:  0.38181818181818183 \n",
      "Avg loss:  2.709506034851074\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.674164  [  928/ 1760]Test: \n",
      "Accuracy:  0.40454545454545454 \n",
      "Avg loss:  2.682371497154236\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.667821  [  928/ 1760]Test: \n",
      "Accuracy:  0.41363636363636364 \n",
      "Avg loss:  2.665590524673462\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.626387  [  928/ 1760]Test: \n",
      "Accuracy:  0.4318181818181818 \n",
      "Avg loss:  2.656056046485901\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.608330  [  928/ 1760]Test: \n",
      "Accuracy:  0.4409090909090909 \n",
      "Avg loss:  2.6331288814544678\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.644764  [  928/ 1760]Test: \n",
      "Accuracy:  0.4590909090909091 \n",
      "Avg loss:  2.613427996635437\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.632550  [  928/ 1760]Test: \n",
      "Accuracy:  0.4636363636363636 \n",
      "Avg loss:  2.599275231361389\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.565964  [  928/ 1760]Test: \n",
      "Accuracy:  0.4727272727272727 \n",
      "Avg loss:  2.5717567205429077\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.621204  [  928/ 1760]Test: \n",
      "Accuracy:  0.4818181818181818 \n",
      "Avg loss:  2.5650054216384888\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.510963  [  928/ 1760]Test: \n",
      "Accuracy:  0.5 \n",
      "Avg loss:  2.545819044113159\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.470945  [  928/ 1760]Test: \n",
      "Accuracy:  0.5136363636363637 \n",
      "Avg loss:  2.532668113708496\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.530827  [  928/ 1760]Test: \n",
      "Accuracy:  0.5363636363636364 \n",
      "Avg loss:  2.5103015899658203\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.581638  [  928/ 1760]Test: \n",
      "Accuracy:  0.5454545454545454 \n",
      "Avg loss:  2.49282968044281\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.491076  [  928/ 1760]Test: \n",
      "Accuracy:  0.5545454545454546 \n",
      "Avg loss:  2.474091649055481\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.496977  [  928/ 1760]Test: \n",
      "Accuracy:  0.5636363636363636 \n",
      "Avg loss:  2.4461519718170166\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.452053  [  928/ 1760]Test: \n",
      "Accuracy:  0.5727272727272728 \n",
      "Avg loss:  2.4269330501556396\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.385275  [  928/ 1760]Test: \n",
      "Accuracy:  0.5772727272727273 \n",
      "Avg loss:  2.4044660329818726\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.419360  [  928/ 1760]Test: \n",
      "Accuracy:  0.5818181818181818 \n",
      "Avg loss:  2.380733609199524\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.427364  [  928/ 1760]Test: \n",
      "Accuracy:  0.5909090909090909 \n",
      "Avg loss:  2.360251307487488\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.314335  [  928/ 1760]Test: \n",
      "Accuracy:  0.5863636363636363 \n",
      "Avg loss:  2.342555522918701\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.268229  [  928/ 1760]Test: \n",
      "Accuracy:  0.6045454545454545 \n",
      "Avg loss:  2.3252530097961426\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.329711  [  928/ 1760]Test: \n",
      "Accuracy:  0.6045454545454545 \n",
      "Avg loss:  2.304562568664551\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.199563  [  928/ 1760]Test: \n",
      "Accuracy:  0.6090909090909091 \n",
      "Avg loss:  2.2845650911331177\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.245910  [  928/ 1760]Test: \n",
      "Accuracy:  0.6090909090909091 \n",
      "Avg loss:  2.2648744583129883\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.141768  [  928/ 1760]Test: \n",
      "Accuracy:  0.6181818181818182 \n",
      "Avg loss:  2.2338967323303223\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.219070  [  928/ 1760]Test: \n",
      "Accuracy:  0.6272727272727273 \n",
      "Avg loss:  2.2127506732940674\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.260004  [  928/ 1760]Test: \n",
      "Accuracy:  0.6272727272727273 \n",
      "Avg loss:  2.1892924308776855\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.116630  [  928/ 1760]Test: \n",
      "Accuracy:  0.6227272727272727 \n",
      "Avg loss:  2.16874623298645\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.127606  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  2.1392911672592163\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.112882  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  2.1298428773880005\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.105588  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  2.103439688682556\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.073295  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  2.095793843269348\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.000201  [  928/ 1760]Test: \n",
      "Accuracy:  0.6590909090909091 \n",
      "Avg loss:  2.0540571212768555\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.088941  [  928/ 1760]Test: \n",
      "Accuracy:  0.6590909090909091 \n",
      "Avg loss:  2.0479629039764404\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.063155  [  928/ 1760]Test: \n",
      "Accuracy:  0.6636363636363637 \n",
      "Avg loss:  2.015778064727783\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.078354  [  928/ 1760]Test: \n",
      "Accuracy:  0.6681818181818182 \n",
      "Avg loss:  1.9969743490219116\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.965711  [  928/ 1760]Test: \n",
      "Accuracy:  0.6772727272727272 \n",
      "Avg loss:  1.9701889753341675\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.901129  [  928/ 1760]Test: \n",
      "Accuracy:  0.6818181818181818 \n",
      "Avg loss:  1.9620243310928345\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.981236  [  928/ 1760]Test: \n",
      "Accuracy:  0.6818181818181818 \n",
      "Avg loss:  1.9340007901191711\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.890537  [  928/ 1760]Test: \n",
      "Accuracy:  0.6772727272727272 \n",
      "Avg loss:  1.898590087890625\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.876763  [  928/ 1760]Test: \n",
      "Accuracy:  0.6818181818181818 \n",
      "Avg loss:  1.8816874027252197\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.809137  [  928/ 1760]Test: \n",
      "Accuracy:  0.6909090909090909 \n",
      "Avg loss:  1.8615719079971313\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.868227  [  928/ 1760]Test: \n",
      "Accuracy:  0.7 \n",
      "Avg loss:  1.8399499654769897\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.763838  [  928/ 1760]Test: \n",
      "Accuracy:  0.7136363636363636 \n",
      "Avg loss:  1.8252304196357727\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.793934  [  928/ 1760]Test: \n",
      "Accuracy:  0.7272727272727273 \n",
      "Avg loss:  1.801573097705841\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.785835  [  928/ 1760]Test: \n",
      "Accuracy:  0.7363636363636363 \n",
      "Avg loss:  1.7816864252090454\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.881722  [  928/ 1760]Test: \n",
      "Accuracy:  0.7454545454545455 \n",
      "Avg loss:  1.762153148651123\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.785631  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.722120761871338\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.716121  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.725689172744751\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.764876  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.7015933990478516\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.751663  [  928/ 1760]Test: \n",
      "Accuracy:  0.759090909090909 \n",
      "Avg loss:  1.6769601702690125\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.612683  [  928/ 1760]Test: \n",
      "Accuracy:  0.7636363636363637 \n",
      "Avg loss:  1.6730398535728455\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.520270  [  928/ 1760]Test: \n",
      "Accuracy:  0.7772727272727272 \n",
      "Avg loss:  1.639714777469635\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.563006  [  928/ 1760]Test: \n",
      "Accuracy:  0.7727272727272727 \n",
      "Avg loss:  1.617350161075592\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.540491  [  928/ 1760]Test: \n",
      "Accuracy:  0.7772727272727272 \n",
      "Avg loss:  1.5985811352729797\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.566512  [  928/ 1760]Test: \n",
      "Accuracy:  0.7954545454545454 \n",
      "Avg loss:  1.5804147720336914\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.624321  [  928/ 1760]Test: \n",
      "Accuracy:  0.8045454545454546 \n",
      "Avg loss:  1.5579463243484497\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.532148  [  928/ 1760]Test: \n",
      "Accuracy:  0.8 \n",
      "Avg loss:  1.5454636812210083\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.511916  [  928/ 1760]Test: \n",
      "Accuracy:  0.8045454545454546 \n",
      "Avg loss:  1.5311078429222107\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.484042  [  928/ 1760]Test: \n",
      "Accuracy:  0.8136363636363636 \n",
      "Avg loss:  1.497164011001587\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.435322  [  928/ 1760]Test: \n",
      "Accuracy:  0.8272727272727273 \n",
      "Avg loss:  1.4903451204299927\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.538579  [  928/ 1760]Test: \n",
      "Accuracy:  0.8227272727272728 \n",
      "Avg loss:  1.471931278705597\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.471974  [  928/ 1760]Test: \n",
      "Accuracy:  0.8227272727272728 \n",
      "Avg loss:  1.456141710281372\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.465926  [  928/ 1760]Test: \n",
      "Accuracy:  0.8227272727272728 \n",
      "Avg loss:  1.4349905252456665\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.344308  [  928/ 1760]Test: \n",
      "Accuracy:  0.8272727272727273 \n",
      "Avg loss:  1.4176599383354187\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.364708  [  928/ 1760]Test: \n",
      "Accuracy:  0.8363636363636363 \n",
      "Avg loss:  1.4091708064079285\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.401877  [  928/ 1760]Test: \n",
      "Accuracy:  0.8363636363636363 \n",
      "Avg loss:  1.3828908205032349\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.371989  [  928/ 1760]Test: \n",
      "Accuracy:  0.85 \n",
      "Avg loss:  1.3735348582267761\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.240234  [  928/ 1760]Test: \n",
      "Accuracy:  0.8590909090909091 \n",
      "Avg loss:  1.3601937294006348\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.322362  [  928/ 1760]Test: \n",
      "Accuracy:  0.8590909090909091 \n",
      "Avg loss:  1.3427516222000122\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.295185  [  928/ 1760]Test: \n",
      "Accuracy:  0.8636363636363636 \n",
      "Avg loss:  1.3193023800849915\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.278412  [  928/ 1760]Test: \n",
      "Accuracy:  0.8636363636363636 \n",
      "Avg loss:  1.2896387577056885\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.333199  [  928/ 1760]Test: \n",
      "Accuracy:  0.8636363636363636 \n",
      "Avg loss:  1.2979912757873535\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.342587  [  928/ 1760]Test: \n",
      "Accuracy:  0.8681818181818182 \n",
      "Avg loss:  1.2751817107200623\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.238557  [  928/ 1760]Test: \n",
      "Accuracy:  0.8772727272727273 \n",
      "Avg loss:  1.2576780915260315\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.292647  [  928/ 1760]Test: \n",
      "Accuracy:  0.8772727272727273 \n",
      "Avg loss:  1.2493040561676025\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.226573  [  928/ 1760]Test: \n",
      "Accuracy:  0.8772727272727273 \n",
      "Avg loss:  1.22701096534729\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.255753  [  928/ 1760]Test: \n",
      "Accuracy:  0.8818181818181818 \n",
      "Avg loss:  1.2182817459106445\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.177134  [  928/ 1760]Test: \n",
      "Accuracy:  0.8818181818181818 \n",
      "Avg loss:  1.2102681398391724\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.207135  [  928/ 1760]Test: \n",
      "Accuracy:  0.8772727272727273 \n",
      "Avg loss:  1.1855356693267822\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.226516  [  928/ 1760]Test: \n",
      "Accuracy:  0.8818181818181818 \n",
      "Avg loss:  1.1732828617095947\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.188508  [  928/ 1760]Test: \n",
      "Accuracy:  0.8818181818181818 \n",
      "Avg loss:  1.1619676351547241\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.195609  [  928/ 1760]Test: \n",
      "Accuracy:  0.8863636363636364 \n",
      "Avg loss:  1.1508382558822632\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.083729  [  928/ 1760]Test: \n",
      "Accuracy:  0.8863636363636364 \n",
      "Avg loss:  1.1494929194450378\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.072749  [  928/ 1760]Test: \n",
      "Accuracy:  0.8954545454545455 \n",
      "Avg loss:  1.1292652487754822\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.089734  [  928/ 1760]Test: \n",
      "Accuracy:  0.8954545454545455 \n",
      "Avg loss:  1.1058600544929504\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.201435  [  928/ 1760]Test: \n",
      "Accuracy:  0.8954545454545455 \n",
      "Avg loss:  1.1109684109687805\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.107155  [  928/ 1760]Test: \n",
      "Accuracy:  0.9 \n",
      "Avg loss:  1.092285692691803\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.063532  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  1.0739679336547852\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.101956  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  1.0657948851585388\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.116574  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  1.0517835021018982\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 1.044236  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  1.0467723608016968\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.044672  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  1.035013198852539\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.050750  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  1.0282458662986755\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.016870  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  1.0099727511405945\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.983647  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.9977479577064514\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.990374  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.9848524332046509\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.951079  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.9774855077266693\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.016764  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.9695185422897339\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.997435  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.9653215110301971\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.979378  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.9530419111251831\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.926894  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.9422593414783478\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.890553  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.9293431043624878\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.934316  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.9209579527378082\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.941912  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.9098595380783081\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.897568  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.9014964699745178\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.944156  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.8925889730453491\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.843496  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.881240576505661\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.915066  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.8708827793598175\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.860406  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.8722296953201294\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.913549  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.8587906062602997\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.795704  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.8465598225593567\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.905379  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.8408926725387573\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.933514  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.8380330502986908\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.814603  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.8250596821308136\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.762600  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.8206920325756073\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.849608  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.8155646622180939\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.778634  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.8092757761478424\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.829429  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.8004573583602905\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.764216  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.7897801101207733\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.736900  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.7909395694732666\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.832875  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.7686982750892639\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.716335  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.7717314660549164\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.762864  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.7619940638542175\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.819115  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7497588098049164\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.726577  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7496114075183868\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.756199  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7348454296588898\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.706756  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7303581833839417\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.684169  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.723575234413147\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.750758  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7288240194320679\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.653125  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7204861044883728\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.727068  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.7091842293739319\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.741386  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.7095373868942261\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.758574  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6936522126197815\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.656276  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.689463347196579\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.743557  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.683431088924408\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.734329  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.6768055260181427\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.703744  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.6668095290660858\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.749666  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.666398286819458\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.680920  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6562633812427521\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.603158  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.6596789360046387\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.690358  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6550234854221344\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.693682  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.644984096288681\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.688058  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6431306600570679\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.691654  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.6391984820365906\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.616842  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.6315264403820038\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.657298  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6215872466564178\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.613899  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6198402345180511\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.665976  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6117716133594513\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.669829  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6098989248275757\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.664516  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.612851619720459\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.571446  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5961343348026276\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.611402  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.6008689701557159\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.630942  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5914129316806793\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.574125  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5848287045955658\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.592366  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5847929120063782\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.563463  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.584117978811264\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.575901  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.575796514749527\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.584631  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.5664458274841309\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.531471  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.565117359161377\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.534080  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5647250413894653\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.526832  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.5581529438495636\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.501884  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5531269609928131\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.612418  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.5433726012706757\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.542954  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5398682951927185\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.586326  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5397121906280518\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.523875  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.5321879386901855\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.564855  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.5359552502632141\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.489594  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.5406473577022552\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.544731  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.5211969166994095\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.555501  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5176989734172821\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.537621  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5140280574560165\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.504519  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5107445120811462\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.517890  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.5108916461467743\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.525188  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.5116656720638275\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.530006  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.5014403313398361\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.484862  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.49318328499794006\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.517562  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.490143746137619\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.456842  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.49782373011112213\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.538734  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.48948973417282104\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.417717  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4874531924724579\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.505357  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.4797797352075577\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.486441  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.48509739339351654\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.466418  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.4818497598171234\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.548592  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.47216111421585083\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.521926  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.46738462150096893\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.494583  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.4696785658597946\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.489921  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.46805424988269806\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.457804  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.4549938440322876\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.491606  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.4601123034954071\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.476898  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.44922251999378204\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.473979  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4540717154741287\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.446354  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4493669420480728\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.510350  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.45237335562705994\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.472208  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.44214746356010437\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.488091  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.43802469968795776\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.470434  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.43954379856586456\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.478127  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4364059418439865\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.461610  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.42758752405643463\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.458165  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.43271735310554504\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.439112  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.42585256695747375\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.436067  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4181073158979416\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.497283  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.41886407136917114\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.416320  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.42026084661483765\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.460544  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.42015618085861206\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.432604  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4134144186973572\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.413090  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.4121799021959305\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.436326  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.4114116132259369\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.429211  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.4075383394956589\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.406557  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.40054744482040405\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.380450  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.39548665285110474\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.396305  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.39787817001342773\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.430319  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.39079107344150543\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.440135  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.38764603435993195\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.376501  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.39308106899261475\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.417469  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3829350769519806\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.376288  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.3817250281572342\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.434312  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.39249132573604584\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.364647  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.38852325081825256\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.401120  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3762747049331665\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.433683  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.38051755726337433\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.377328  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.377506360411644\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.384973  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.37318255007267\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.433317  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3674149215221405\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.438622  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.37476202845573425\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.431935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.36440376937389374\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.395901  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.3639051616191864\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.319121  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3655267208814621\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.418597  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.36279192566871643\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.388912  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3527936339378357\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.300373  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.35673603415489197\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.359825  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.36173559725284576\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.333413  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.35419219732284546\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.363792  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3586089313030243\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.385584  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3492553234100342\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.354025  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3548991233110428\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.387756  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3447248935699463\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.399170  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3521638810634613\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.357083  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.33593590557575226\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.338859  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.33758531510829926\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.339386  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3369484543800354\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.339347  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3429933041334152\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.328521  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.33725404739379883\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.351695  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3385034501552582\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.361428  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.32973456382751465\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.352535  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.32566480338573456\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.351882  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.32871396839618683\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.361894  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3257133811712265\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.345771  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.3236701339483261\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.373245  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3275288790464401\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.385890  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.32194867730140686\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.308606  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3215368241071701\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.351375  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.3202468901872635\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.336611  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.32175515592098236\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.352028  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.32019077241420746\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.374538  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.31818364560604095\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.379195  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3118268847465515\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.351490  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3075496256351471\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.302183  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.30780990421772003\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.352744  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3064894378185272\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.314425  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.30501486361026764\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.337739  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.3077457696199417\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.315171  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2996308505535126\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.328513  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.29864074289798737\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.330479  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.29935333132743835\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.312122  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.29217900335788727\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.317492  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.30232641100883484\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.288923  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.29549939930438995\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.302341  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.29223956167697906\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.378081  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2902594059705734\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.252041  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2886611372232437\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.290629  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2943050414323807\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.335350  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2878721058368683\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.245134  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2895284742116928\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.320596  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.29139646887779236\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.306622  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.28349678218364716\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.277256  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.28506770730018616\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.307300  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2867481857538223\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.288740  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.28729134798049927\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.269371  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2846733629703522\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.274150  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2770174592733383\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.254803  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2803197354078293\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.329238  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.27558329701423645\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279321  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.27850495278835297\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279490  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.27006398141384125\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.301131  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.273116335272789\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.280787  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.26980064809322357\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.311716  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2751396894454956\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.290523  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.269846573472023\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.320764  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2717514783143997\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.280687  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.26823312044143677\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.297397  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.26224103569984436\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.276221  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2643796056509018\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.282532  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.26212141662836075\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.325250  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.26926059275865555\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.286670  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.26005591452121735\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.239158  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.25975850224494934\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.283424  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.260757714509964\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.247314  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.25471726804971695\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.338815  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2615896314382553\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279162  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2560376524925232\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.290257  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2548133283853531\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.261092  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2546979486942291\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.248883  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.25480368733406067\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.258430  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2565245032310486\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.288431  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.25034285336732864\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.219916  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2563932090997696\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.247208  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2507360726594925\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.261405  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.24821698665618896\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.298349  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.24228321760892868\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.240647  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.24597623199224472\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.208234  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.24822211265563965\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.258412  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2404778078198433\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.245762  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.24243676662445068\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.255406  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2428385615348816\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.256508  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.23823197185993195\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.248465  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2413632571697235\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.244372  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.23918697983026505\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.262392  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2364761233329773\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.262704  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.24338989704847336\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.298690  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2359752580523491\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.277506  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.24018782377243042\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235079  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2341030091047287\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211430  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.23151055723428726\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.223382  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.23323628306388855\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.227029  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.22868278622627258\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.199611  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.23669998347759247\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.251483  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.224540077149868\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.240054  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.23061975836753845\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.258557  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2310582995414734\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.242976  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.22375308722257614\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221869  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.22888295352458954\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.285401  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.22625943273305893\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.246309  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.22201650589704514\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.257022  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.22887316346168518\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.218382  [  928/ 1760]Test: \n",
      "Accuracy:  0.9681818181818181 \n",
      "Avg loss:  0.2238195836544037\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.226628  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.22234686464071274\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221753  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21938854455947876\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.216183  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21790014952421188\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.226812  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.22489652037620544\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.201632  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.22391504794359207\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235884  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21374092996120453\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221209  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.21964453905820847\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.250408  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21762532740831375\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.223277  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21235980838537216\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.161756  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21554091572761536\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.213696  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.21005167067050934\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.242379  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21484940499067307\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221530  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.2152535319328308\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.229469  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.21066290885210037\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235767  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.2147386148571968\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.209599  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.21260052919387817\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.212932  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21404778957366943\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.218048  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21563303470611572\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.224221  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.21008246392011642\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.204160  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.2090458795428276\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.217039  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.21210722625255585\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.240576  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20441650599241257\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.272426  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20325839519500732\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.200676  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.2044820562005043\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.199546  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20901386439800262\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20579352229833603\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188794  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.2029348760843277\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.242034  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20518575608730316\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.240430  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.204106405377388\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.209493  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.20458675920963287\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.292217  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1978781521320343\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.193001  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.19892562925815582\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.253034  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.20031583309173584\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.227098  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19725016504526138\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.243502  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19801128655672073\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.223716  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19578547775745392\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235348  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.196367546916008\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.257521  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.19076064229011536\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.175909  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1959741786122322\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188001  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19465043395757675\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211355  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19387443363666534\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211471  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19122513383626938\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221280  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1941576823592186\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221535  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18682169914245605\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.205834  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19395549595355988\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.175447  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19022712111473083\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.162989  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.193491593003273\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.199941  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1927940845489502\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169302  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19374769926071167\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.161974  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18737497925758362\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.174731  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.19087780267000198\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.179027  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18939001113176346\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.219078  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.18730521202087402\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.230049  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18630651384592056\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.251765  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18839188665151596\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.192720  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18089620023965836\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.183001  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17899201810359955\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.151834  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17859260737895966\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.241485  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.1843007653951645\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.204744  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18154561519622803\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.190853  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18273120373487473\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.261101  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18052569776773453\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.165615  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.182304747402668\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.166659  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18060347437858582\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.194585  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18027377128601074\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.186152  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.1798103004693985\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.172373  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1772177442908287\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.150615  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1761225014925003\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.202719  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1720709428191185\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.162414  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17588545382022858\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.158992  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.18031766265630722\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187069  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1713712066411972\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.200763  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.17688503861427307\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187797  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17933230847120285\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.163762  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1715642511844635\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188328  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1781134158372879\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.216473  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16926567256450653\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.157703  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1774233728647232\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.176618  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1778222769498825\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.182234  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16881844401359558\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.209338  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.1725579798221588\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.209247  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16978077590465546\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.182890  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17560039460659027\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.153856  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16836455464363098\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.167728  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17152243107557297\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.165480  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16909687966108322\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.149311  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1714261770248413\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.201624  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.17049847543239594\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.200280  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16324787586927414\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.167993  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16817926615476608\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16779640316963196\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.189146  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16521568596363068\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.151441  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16679548472166061\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.168899  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1636878103017807\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.167967  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1679706647992134\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.231950  [  928/ 1760]Test: \n",
      "Accuracy:  0.9772727272727273 \n",
      "Avg loss:  0.16336169093847275\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187707  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16199684143066406\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.172518  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1663457602262497\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.202251  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1580151915550232\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.162937  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16362541913986206\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169795  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1640564277768135\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.175671  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15864663571119308\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.178101  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16036175191402435\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.153307  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16055746376514435\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.196170  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1606970801949501\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.148292  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1602068915963173\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.186475  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16010824590921402\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.222072  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16023533046245575\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.130611  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16398506611585617\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.143487  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1657022386789322\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.137317  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15327803790569305\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.148420  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15505962818861008\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.184935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1542266309261322\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.189292  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.16089513152837753\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.173900  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1603398248553276\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.134034  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15665265172719955\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.135426  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15627016872167587\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.186824  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15155202895402908\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.258057  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15346946567296982\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.164884  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.15035762637853622\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.141935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.152048721909523\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.183825  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.1542765572667122\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.161777  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.14963387697935104\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.149579  [  928/ 1760]Test: \n",
      "Accuracy:  0.9727272727272728 \n",
      "Avg loss:  0.14601164311170578\n",
      "\n",
      "\n",
      "\n",
      "Validation Data: \n",
      "Test: \n",
      "Accuracy:  0.9863636363636363 \n",
      "Avg loss:  0.17504820227622986\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    print(\"\")\n",
    "    train_loop(train_data_loader)\n",
    "    test_loop(test_data_loader)\n",
    "\n",
    "print(\"\\n\\n\\nValidation Data: \")\n",
    "test_loop(validation_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:28:02.315447Z",
     "start_time": "2024-05-04T09:26:57.756453Z"
    }
   },
   "id": "d2e4f33c43d0c1a9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'model.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:34:36.806847Z",
     "start_time": "2024-05-04T09:34:36.748403Z"
    }
   },
   "id": "f60ce7e18e93d566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3fd8469909d5881"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
