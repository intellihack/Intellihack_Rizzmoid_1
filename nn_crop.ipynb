{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:48.153071Z",
     "start_time": "2024-05-04T09:08:47.219370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1760, 12), (220, 12), (220, 12))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Crop_Dataset.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, train_size=0.8)\n",
    "validation_data, test_data = train_test_split(test_data, train_size=0.5)\n",
    "\n",
    "train_data.shape, test_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(data['Label_Encoded'].unique())\n",
    "n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:48.155578Z",
     "start_time": "2024-05-04T09:08:48.152853Z"
    }
   },
   "id": "134db0c50579d075"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"mps\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:50.829346Z",
     "start_time": "2024-05-04T09:08:48.156638Z"
    }
   },
   "id": "25c98d5511cd1168"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.inputs = data.iloc[:, 0:-2].values.astype('float32')\n",
    "        \n",
    "        # for i in range(self.inputs.shape[1]):\n",
    "        #     self.inputs[:, i] = normalize(torch.tensor(self.inputs[:, i].reshape(-1, 1)), dim=0).reshape(-1)\n",
    "        \n",
    "        for i in range(self.inputs.shape[1]):\n",
    "            max_val = self.inputs[:, i].max()\n",
    "            min_val = self.inputs[:, i].min()\n",
    "            self.inputs[:, i] = (self.inputs[:, i] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        self.outputs = data.iloc[:, -1].values.astype('int')\n",
    "        \n",
    "        self.inputs = torch.tensor(self.inputs, device=device)\n",
    "        self.outputs = torch.tensor(self.outputs, device=device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:50.837784Z",
     "start_time": "2024-05-04T09:08:50.830581Z"
    }
   },
   "id": "6f491ad7458c9537"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(CustomDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(CustomDataset(test_data), batch_size=batch_size, shuffle=True)\n",
    "validation_data_loader = torch.utils.data.DataLoader(CustomDataset(validation_data), batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:50.946238Z",
     "start_time": "2024-05-04T09:08:50.839855Z"
    }
   },
   "id": "97345e2e0fba23c6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([128, 10])\n",
      "Shape of y:  torch.Size([128]) torch.int64\n",
      "Sample X:  tensor([0.0429, 0.4786, 0.0500, 0.4103, 0.6119, 0.6478, 0.1243, 0.2044, 0.3362,\n",
      "        0.3644], device='mps:0')\n",
      "Sample y:  tensor(8, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# print shapes and samples from the dataset\n",
    "for X, y in train_data_loader:\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    print(\"Sample X: \", X[0])\n",
    "    print(\"Sample y: \", y[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:51.241828Z",
     "start_time": "2024-05-04T09:08:50.947564Z"
    }
   },
   "id": "5545db8d69fbc4fa"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 22),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:51.241965Z",
     "start_time": "2024-05-04T09:08:51.238847Z"
    }
   },
   "id": "c232c3144a1df0d6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=22, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:51.248390Z",
     "start_time": "2024-05-04T09:08:51.241234Z"
    }
   },
   "id": "c272fb94daa41e97"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([19], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# testing predictions\n",
    "\n",
    "_X = torch.rand(1, 10, device=device)\n",
    "logits = model(_X)\n",
    "predicted_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = predicted_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:51.312443Z",
     "start_time": "2024-05-04T09:08:51.250904Z"
    }
   },
   "id": "100378c7ad3a6a73"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:51.320691Z",
     "start_time": "2024-05-04T09:08:51.314087Z"
    }
   },
   "id": "4993b936e24ca0f3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlakshith\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/lakshithnishshanke/Developer/Intellihack/Intellihack_Rizzmoid_1/wandb/run-20240504_143852-8q0pa503</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='http://localhost:8080/lakshith/Intellihack_1/runs/8q0pa503' target=\"_blank\">galactic-republic-23</a></strong> to <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='http://localhost:8080/lakshith/Intellihack_1/runs/8q0pa503' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1/runs/8q0pa503</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='http://localhost:8080/lakshith/Intellihack_1/runs/8q0pa503?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x13d959280>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "configs = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"ANN\",\n",
    "    \"dataset\": \"Crop\",\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Intellihack_1\",\n",
    "    config=configs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:57.344269Z",
     "start_time": "2024-05-04T09:08:51.316790Z"
    }
   },
   "id": "3f08bf8faaddb863"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_loop(dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, current = loss.item(), batch * batch_size + len(X)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Loss\": loss\n",
    "        })\n",
    "        print(f\"\\rloss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:57.345273Z",
     "start_time": "2024-05-04T09:08:57.319142Z"
    }
   },
   "id": "263db61f89b14c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test_loop(dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    wandb.log({\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"Test Accuracy\": correct\n",
    "    })\n",
    "    \n",
    "    print(\"Test: \\nAccuracy: \", correct, \"\\nAvg loss: \", test_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:57.346128Z",
     "start_time": "2024-05-04T09:08:57.339281Z"
    }
   },
   "id": "7a025d958375368f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:08:57.373128Z",
     "start_time": "2024-05-04T09:08:57.345135Z"
    }
   },
   "id": "919104987103baeb"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.092394  [  928/ 1760]Test: \n",
      "Accuracy:  0.08636363636363636 \n",
      "Avg loss:  3.082542061805725\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.071829  [  928/ 1760]Test: \n",
      "Accuracy:  0.08181818181818182 \n",
      "Avg loss:  3.074304938316345\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.052243  [  928/ 1760]Test: \n",
      "Accuracy:  0.08181818181818182 \n",
      "Avg loss:  3.064993143081665\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.048591  [  928/ 1760]Test: \n",
      "Accuracy:  0.09545454545454546 \n",
      "Avg loss:  3.0603822469711304\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.058642  [  928/ 1760]Test: \n",
      "Accuracy:  0.11818181818181818 \n",
      "Avg loss:  3.0514646768569946\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.047478  [  928/ 1760]Test: \n",
      "Accuracy:  0.14545454545454545 \n",
      "Avg loss:  3.0442930459976196\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.027323  [  928/ 1760]Test: \n",
      "Accuracy:  0.14545454545454545 \n",
      "Avg loss:  3.0354868173599243\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.019739  [  928/ 1760]Test: \n",
      "Accuracy:  0.14545454545454545 \n",
      "Avg loss:  3.0276588201522827\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.011373  [  928/ 1760]Test: \n",
      "Accuracy:  0.15 \n",
      "Avg loss:  3.021600127220154\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.008881  [  928/ 1760]Test: \n",
      "Accuracy:  0.15 \n",
      "Avg loss:  3.012324333190918\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.014497  [  928/ 1760]Test: \n",
      "Accuracy:  0.15454545454545454 \n",
      "Avg loss:  3.0075390338897705\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.978990  [  928/ 1760]Test: \n",
      "Accuracy:  0.15454545454545454 \n",
      "Avg loss:  2.9993845224380493\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.978687  [  928/ 1760]Test: \n",
      "Accuracy:  0.16363636363636364 \n",
      "Avg loss:  2.9921908378601074\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.984772  [  928/ 1760]Test: \n",
      "Accuracy:  0.16818181818181818 \n",
      "Avg loss:  2.984435796737671\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.955379  [  928/ 1760]Test: \n",
      "Accuracy:  0.17272727272727273 \n",
      "Avg loss:  2.9773131608963013\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.966900  [  928/ 1760]Test: \n",
      "Accuracy:  0.17272727272727273 \n",
      "Avg loss:  2.969783067703247\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.963585  [  928/ 1760]Test: \n",
      "Accuracy:  0.18181818181818182 \n",
      "Avg loss:  2.961941361427307\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.952684  [  928/ 1760]Test: \n",
      "Accuracy:  0.20454545454545456 \n",
      "Avg loss:  2.9534796476364136\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.927366  [  928/ 1760]Test: \n",
      "Accuracy:  0.21363636363636362 \n",
      "Avg loss:  2.9434534311294556\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.962631  [  928/ 1760]Test: \n",
      "Accuracy:  0.22272727272727272 \n",
      "Avg loss:  2.935288429260254\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.936040  [  928/ 1760]Test: \n",
      "Accuracy:  0.2318181818181818 \n",
      "Avg loss:  2.9242156744003296\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.905457  [  928/ 1760]Test: \n",
      "Accuracy:  0.25 \n",
      "Avg loss:  2.912453293800354\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.905582  [  928/ 1760]Test: \n",
      "Accuracy:  0.2590909090909091 \n",
      "Avg loss:  2.9008893966674805\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.907547  [  928/ 1760]Test: \n",
      "Accuracy:  0.2772727272727273 \n",
      "Avg loss:  2.893216848373413\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.866442  [  928/ 1760]Test: \n",
      "Accuracy:  0.2863636363636364 \n",
      "Avg loss:  2.878642201423645\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.864827  [  928/ 1760]Test: \n",
      "Accuracy:  0.3 \n",
      "Avg loss:  2.872783899307251\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.888195  [  928/ 1760]Test: \n",
      "Accuracy:  0.32272727272727275 \n",
      "Avg loss:  2.8570109605789185\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.808921  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.8428683280944824\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.836133  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.8356895446777344\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.820508  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.8238232135772705\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.828689  [  928/ 1760]Test: \n",
      "Accuracy:  0.35454545454545455 \n",
      "Avg loss:  2.8043718338012695\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.791072  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.7913856506347656\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.767175  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.785282850265503\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.763125  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.7730560302734375\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.745104  [  928/ 1760]Test: \n",
      "Accuracy:  0.35454545454545455 \n",
      "Avg loss:  2.754162907600403\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.697904  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.7345625162124634\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.744523  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.727834939956665\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.745273  [  928/ 1760]Test: \n",
      "Accuracy:  0.35 \n",
      "Avg loss:  2.7005704641342163\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.708096  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.6944687366485596\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.653542  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.6798481941223145\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.654029  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.659184217453003\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.615109  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.634868860244751\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.604324  [  928/ 1760]Test: \n",
      "Accuracy:  0.33636363636363636 \n",
      "Avg loss:  2.628684401512146\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.606103  [  928/ 1760]Test: \n",
      "Accuracy:  0.33636363636363636 \n",
      "Avg loss:  2.615841269493103\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.556629  [  928/ 1760]Test: \n",
      "Accuracy:  0.33181818181818185 \n",
      "Avg loss:  2.5967090129852295\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.453522  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.57547926902771\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.523230  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.5568443536758423\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.522935  [  928/ 1760]Test: \n",
      "Accuracy:  0.34545454545454546 \n",
      "Avg loss:  2.5407882928848267\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.576766  [  928/ 1760]Test: \n",
      "Accuracy:  0.3409090909090909 \n",
      "Avg loss:  2.5196359157562256\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.525910  [  928/ 1760]Test: \n",
      "Accuracy:  0.35454545454545455 \n",
      "Avg loss:  2.4985177516937256\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.508885  [  928/ 1760]Test: \n",
      "Accuracy:  0.35454545454545455 \n",
      "Avg loss:  2.486984610557556\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.500282  [  928/ 1760]Test: \n",
      "Accuracy:  0.35454545454545455 \n",
      "Avg loss:  2.457942843437195\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.443694  [  928/ 1760]Test: \n",
      "Accuracy:  0.35909090909090907 \n",
      "Avg loss:  2.45001757144928\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.429211  [  928/ 1760]Test: \n",
      "Accuracy:  0.36818181818181817 \n",
      "Avg loss:  2.424744725227356\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.416100  [  928/ 1760]Test: \n",
      "Accuracy:  0.36818181818181817 \n",
      "Avg loss:  2.401053309440613\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.387295  [  928/ 1760]Test: \n",
      "Accuracy:  0.38636363636363635 \n",
      "Avg loss:  2.394476532936096\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.407372  [  928/ 1760]Test: \n",
      "Accuracy:  0.39090909090909093 \n",
      "Avg loss:  2.3662840127944946\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.400131  [  928/ 1760]Test: \n",
      "Accuracy:  0.39545454545454545 \n",
      "Avg loss:  2.3566482067108154\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.238304  [  928/ 1760]Test: \n",
      "Accuracy:  0.39545454545454545 \n",
      "Avg loss:  2.3244279623031616\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.225209  [  928/ 1760]Test: \n",
      "Accuracy:  0.40454545454545454 \n",
      "Avg loss:  2.3198401927948\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.234008  [  928/ 1760]Test: \n",
      "Accuracy:  0.40454545454545454 \n",
      "Avg loss:  2.279295325279236\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.313183  [  928/ 1760]Test: \n",
      "Accuracy:  0.4318181818181818 \n",
      "Avg loss:  2.2688066959381104\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.223609  [  928/ 1760]Test: \n",
      "Accuracy:  0.44545454545454544 \n",
      "Avg loss:  2.2459828853607178\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.232320  [  928/ 1760]Test: \n",
      "Accuracy:  0.45454545454545453 \n",
      "Avg loss:  2.230581283569336\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.229809  [  928/ 1760]Test: \n",
      "Accuracy:  0.45454545454545453 \n",
      "Avg loss:  2.20773446559906\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.232539  [  928/ 1760]Test: \n",
      "Accuracy:  0.4681818181818182 \n",
      "Avg loss:  2.1868194341659546\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.031205  [  928/ 1760]Test: \n",
      "Accuracy:  0.4772727272727273 \n",
      "Avg loss:  2.167037844657898\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.105820  [  928/ 1760]Test: \n",
      "Accuracy:  0.4818181818181818 \n",
      "Avg loss:  2.1396833658218384\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.237187  [  928/ 1760]Test: \n",
      "Accuracy:  0.4909090909090909 \n",
      "Avg loss:  2.1227993965148926\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.032708  [  928/ 1760]Test: \n",
      "Accuracy:  0.4863636363636364 \n",
      "Avg loss:  2.10628342628479\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.128781  [  928/ 1760]Test: \n",
      "Accuracy:  0.5045454545454545 \n",
      "Avg loss:  2.0845463275909424\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.096899  [  928/ 1760]Test: \n",
      "Accuracy:  0.5272727272727272 \n",
      "Avg loss:  2.056293249130249\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.993409  [  928/ 1760]Test: \n",
      "Accuracy:  0.5454545454545454 \n",
      "Avg loss:  2.036076545715332\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.028907  [  928/ 1760]Test: \n",
      "Accuracy:  0.5636363636363636 \n",
      "Avg loss:  2.0111700296401978\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.952145  [  928/ 1760]Test: \n",
      "Accuracy:  0.5636363636363636 \n",
      "Avg loss:  1.9851442575454712\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.953598  [  928/ 1760]Test: \n",
      "Accuracy:  0.5636363636363636 \n",
      "Avg loss:  1.9719045162200928\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.936587  [  928/ 1760]Test: \n",
      "Accuracy:  0.5636363636363636 \n",
      "Avg loss:  1.9425916075706482\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.928596  [  928/ 1760]Test: \n",
      "Accuracy:  0.5681818181818182 \n",
      "Avg loss:  1.929468035697937\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.901968  [  928/ 1760]Test: \n",
      "Accuracy:  0.5772727272727273 \n",
      "Avg loss:  1.905612826347351\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.869243  [  928/ 1760]Test: \n",
      "Accuracy:  0.5772727272727273 \n",
      "Avg loss:  1.8750378489494324\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.809294  [  928/ 1760]Test: \n",
      "Accuracy:  0.5818181818181818 \n",
      "Avg loss:  1.8613256812095642\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.902919  [  928/ 1760]Test: \n",
      "Accuracy:  0.6045454545454545 \n",
      "Avg loss:  1.8413134217262268\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.672294  [  928/ 1760]Test: \n",
      "Accuracy:  0.6318181818181818 \n",
      "Avg loss:  1.8207696080207825\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.764823  [  928/ 1760]Test: \n",
      "Accuracy:  0.6227272727272727 \n",
      "Avg loss:  1.8057650923728943\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.737177  [  928/ 1760]Test: \n",
      "Accuracy:  0.6318181818181818 \n",
      "Avg loss:  1.7791135907173157\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.719432  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  1.764542818069458\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.723170  [  928/ 1760]Test: \n",
      "Accuracy:  0.6409090909090909 \n",
      "Avg loss:  1.7293349504470825\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.790733  [  928/ 1760]Test: \n",
      "Accuracy:  0.6454545454545455 \n",
      "Avg loss:  1.71523118019104\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.645201  [  928/ 1760]Test: \n",
      "Accuracy:  0.6545454545454545 \n",
      "Avg loss:  1.6852525472640991\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.563812  [  928/ 1760]Test: \n",
      "Accuracy:  0.6681818181818182 \n",
      "Avg loss:  1.667799711227417\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.565080  [  928/ 1760]Test: \n",
      "Accuracy:  0.6681818181818182 \n",
      "Avg loss:  1.6611708402633667\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.596637  [  928/ 1760]Test: \n",
      "Accuracy:  0.6772727272727272 \n",
      "Avg loss:  1.6333758234977722\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.550428  [  928/ 1760]Test: \n",
      "Accuracy:  0.6863636363636364 \n",
      "Avg loss:  1.6046608090400696\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.560250  [  928/ 1760]Test: \n",
      "Accuracy:  0.6863636363636364 \n",
      "Avg loss:  1.5936355590820312\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.576138  [  928/ 1760]Test: \n",
      "Accuracy:  0.6863636363636364 \n",
      "Avg loss:  1.579228937625885\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.483256  [  928/ 1760]Test: \n",
      "Accuracy:  0.7090909090909091 \n",
      "Avg loss:  1.5641021132469177\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.397229  [  928/ 1760]Test: \n",
      "Accuracy:  0.7090909090909091 \n",
      "Avg loss:  1.5511837601661682\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.528139  [  928/ 1760]Test: \n",
      "Accuracy:  0.7181818181818181 \n",
      "Avg loss:  1.5210849046707153\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.430914  [  928/ 1760]Test: \n",
      "Accuracy:  0.7363636363636363 \n",
      "Avg loss:  1.4994217157363892\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.543893  [  928/ 1760]Test: \n",
      "Accuracy:  0.75 \n",
      "Avg loss:  1.4806012511253357\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.500134  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.4603227972984314\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.404914  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.4452239871025085\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.395554  [  928/ 1760]Test: \n",
      "Accuracy:  0.759090909090909 \n",
      "Avg loss:  1.436402440071106\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.369435  [  928/ 1760]Test: \n",
      "Accuracy:  0.7545454545454545 \n",
      "Avg loss:  1.4212773442268372\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 1.267585  [  928/ 1760]Test: \n",
      "Accuracy:  0.7454545454545455 \n",
      "Avg loss:  1.410620927810669\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.363849  [  928/ 1760]Test: \n",
      "Accuracy:  0.7818181818181819 \n",
      "Avg loss:  1.3914093375205994\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.421105  [  928/ 1760]Test: \n",
      "Accuracy:  0.7863636363636364 \n",
      "Avg loss:  1.3598623871803284\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.345096  [  928/ 1760]Test: \n",
      "Accuracy:  0.7909090909090909 \n",
      "Avg loss:  1.3501410484313965\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.281901  [  928/ 1760]Test: \n",
      "Accuracy:  0.7863636363636364 \n",
      "Avg loss:  1.3397549986839294\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.469988  [  928/ 1760]Test: \n",
      "Accuracy:  0.7909090909090909 \n",
      "Avg loss:  1.3193954229354858\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.325722  [  928/ 1760]Test: \n",
      "Accuracy:  0.7909090909090909 \n",
      "Avg loss:  1.3025584816932678\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.371852  [  928/ 1760]Test: \n",
      "Accuracy:  0.8 \n",
      "Avg loss:  1.3044996857643127\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.316953  [  928/ 1760]Test: \n",
      "Accuracy:  0.7954545454545454 \n",
      "Avg loss:  1.278640866279602\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.297570  [  928/ 1760]Test: \n",
      "Accuracy:  0.8 \n",
      "Avg loss:  1.2682308554649353\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.292511  [  928/ 1760]Test: \n",
      "Accuracy:  0.8045454545454546 \n",
      "Avg loss:  1.2485676407814026\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.215058  [  928/ 1760]Test: \n",
      "Accuracy:  0.8045454545454546 \n",
      "Avg loss:  1.2341553568840027\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.213024  [  928/ 1760]Test: \n",
      "Accuracy:  0.8136363636363636 \n",
      "Avg loss:  1.222888708114624\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.191923  [  928/ 1760]Test: \n",
      "Accuracy:  0.8181818181818182 \n",
      "Avg loss:  1.2094817757606506\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.155053  [  928/ 1760]Test: \n",
      "Accuracy:  0.8136363636363636 \n",
      "Avg loss:  1.2002015709877014\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.186561  [  928/ 1760]Test: \n",
      "Accuracy:  0.8090909090909091 \n",
      "Avg loss:  1.1868077516555786\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.133877  [  928/ 1760]Test: \n",
      "Accuracy:  0.8090909090909091 \n",
      "Avg loss:  1.1762027144432068\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.153813  [  928/ 1760]Test: \n",
      "Accuracy:  0.8090909090909091 \n",
      "Avg loss:  1.153525471687317\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.007549  [  928/ 1760]Test: \n",
      "Accuracy:  0.8181818181818182 \n",
      "Avg loss:  1.1471035480499268\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.162421  [  928/ 1760]Test: \n",
      "Accuracy:  0.8318181818181818 \n",
      "Avg loss:  1.142252802848816\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.101901  [  928/ 1760]Test: \n",
      "Accuracy:  0.8409090909090909 \n",
      "Avg loss:  1.1157544255256653\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.051745  [  928/ 1760]Test: \n",
      "Accuracy:  0.8318181818181818 \n",
      "Avg loss:  1.1150687336921692\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.117930  [  928/ 1760]Test: \n",
      "Accuracy:  0.8363636363636363 \n",
      "Avg loss:  1.0912300944328308\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.022580  [  928/ 1760]Test: \n",
      "Accuracy:  0.8409090909090909 \n",
      "Avg loss:  1.0847999453544617\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 1.042548  [  928/ 1760]Test: \n",
      "Accuracy:  0.8363636363636363 \n",
      "Avg loss:  1.0756377577781677\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.069394  [  928/ 1760]Test: \n",
      "Accuracy:  0.8363636363636363 \n",
      "Avg loss:  1.0586174130439758\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.052103  [  928/ 1760]Test: \n",
      "Accuracy:  0.8454545454545455 \n",
      "Avg loss:  1.0507022738456726\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.970113  [  928/ 1760]Test: \n",
      "Accuracy:  0.8590909090909091 \n",
      "Avg loss:  1.0314575731754303\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.063159  [  928/ 1760]Test: \n",
      "Accuracy:  0.8590909090909091 \n",
      "Avg loss:  1.0225774347782135\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.026628  [  928/ 1760]Test: \n",
      "Accuracy:  0.8681818181818182 \n",
      "Avg loss:  1.0174527764320374\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.020939  [  928/ 1760]Test: \n",
      "Accuracy:  0.8772727272727273 \n",
      "Avg loss:  0.998499870300293\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.978423  [  928/ 1760]Test: \n",
      "Accuracy:  0.8727272727272727 \n",
      "Avg loss:  0.9894639551639557\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.019500  [  928/ 1760]Test: \n",
      "Accuracy:  0.8681818181818182 \n",
      "Avg loss:  0.9929846823215485\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.030108  [  928/ 1760]Test: \n",
      "Accuracy:  0.8863636363636364 \n",
      "Avg loss:  0.976497620344162\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.899726  [  928/ 1760]Test: \n",
      "Accuracy:  0.9 \n",
      "Avg loss:  0.9645392298698425\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.042685  [  928/ 1760]Test: \n",
      "Accuracy:  0.8954545454545455 \n",
      "Avg loss:  0.9537776708602905\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.856599  [  928/ 1760]Test: \n",
      "Accuracy:  0.9 \n",
      "Avg loss:  0.9413099586963654\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.979557  [  928/ 1760]Test: \n",
      "Accuracy:  0.9 \n",
      "Avg loss:  0.9393648505210876\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.895297  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.9275548160076141\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.904244  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.9258722364902496\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.900344  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.9142212867736816\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.863226  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.9037960171699524\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.890534  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8993710279464722\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.865529  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8889414370059967\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.880391  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.8843607306480408\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.882510  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.8713502883911133\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.919676  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.8578773736953735\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.843242  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.8561432361602783\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.835954  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.8445094525814056\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.849736  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8399064242839813\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.735689  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.8287299573421478\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.818661  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8282626271247864\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.795501  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.8043149709701538\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.785357  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8008798360824585\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.734989  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.8006314337253571\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.810931  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.7987231314182281\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.758233  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.7838446199893951\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.732522  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.7819264531135559\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.685055  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.772373229265213\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.777358  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.7696219682693481\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.719685  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.7576558291912079\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.762358  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.7508133053779602\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.771574  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.745675653219223\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.779213  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.7401054203510284\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.695579  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.7305522859096527\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.736046  [  928/ 1760]Test: \n",
      "Accuracy:  0.9045454545454545 \n",
      "Avg loss:  0.7203724086284637\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.707583  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.7284194529056549\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.737714  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.7104958593845367\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.661355  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.705037385225296\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.727827  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.7053198218345642\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.728935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9090909090909091 \n",
      "Avg loss:  0.700957864522934\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.647218  [  928/ 1760]Test: \n",
      "Accuracy:  0.9136363636363637 \n",
      "Avg loss:  0.7088809609413147\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.736168  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.6876308619976044\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.727112  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.6841770112514496\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.659628  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.6762745082378387\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.702685  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.6663756668567657\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.620002  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.6639777421951294\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.679457  [  928/ 1760]Test: \n",
      "Accuracy:  0.9227272727272727 \n",
      "Avg loss:  0.6589206755161285\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.694111  [  928/ 1760]Test: \n",
      "Accuracy:  0.9181818181818182 \n",
      "Avg loss:  0.6506639719009399\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.666374  [  928/ 1760]Test: \n",
      "Accuracy:  0.9227272727272727 \n",
      "Avg loss:  0.6523607075214386\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.638369  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.6424427032470703\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.652332  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.633257657289505\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.618949  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.6374678611755371\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.635324  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.623929351568222\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.620726  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.6193763911724091\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.639176  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.6185166835784912\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.689516  [  928/ 1760]Test: \n",
      "Accuracy:  0.9227272727272727 \n",
      "Avg loss:  0.6232264637947083\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.650617  [  928/ 1760]Test: \n",
      "Accuracy:  0.9272727272727272 \n",
      "Avg loss:  0.6064904630184174\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.562551  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.5967243015766144\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.612065  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.6031635403633118\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.630549  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.598217248916626\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.689979  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.5969878137111664\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.556996  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5814456045627594\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.589905  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.5820501446723938\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.564762  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5792073309421539\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.515035  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5709307491779327\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.550048  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.5759039223194122\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.546358  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5720435678958893\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.502031  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5643585324287415\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.517935  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5549219846725464\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.634941  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5601569712162018\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.560491  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5520091652870178\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.534779  [  928/ 1760]Test: \n",
      "Accuracy:  0.9318181818181818 \n",
      "Avg loss:  0.5466307997703552\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.570860  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5416236817836761\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.471154  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5449628829956055\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.562218  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5366212427616119\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.567564  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5247837156057358\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.505428  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5317374169826508\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.507521  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5291945040225983\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.513564  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5249136388301849\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.500401  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5182409882545471\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.485189  [  928/ 1760]Test: \n",
      "Accuracy:  0.9409090909090909 \n",
      "Avg loss:  0.5125061869621277\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.457170  [  928/ 1760]Test: \n",
      "Accuracy:  0.9363636363636364 \n",
      "Avg loss:  0.5047700852155685\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.446401  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5131198912858963\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.508246  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.49918702244758606\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.467576  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.5067263841629028\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.501125  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4926288574934006\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.497050  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.49368536472320557\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.516212  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.494577094912529\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.492095  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.48833587765693665\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.499039  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4864498972892761\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.493180  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4778429716825485\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.534811  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4775910973548889\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.470335  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4816250503063202\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.467996  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4723503440618515\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.522862  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4623632878065109\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.494273  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4656916856765747\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.420673  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.45870286226272583\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.491748  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.46303318440914154\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.485145  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4572560340166092\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.438856  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.45417073369026184\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.434661  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.45132923126220703\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.410851  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.45019741356372833\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.402824  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4401894062757492\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.414567  [  928/ 1760]Test: \n",
      "Accuracy:  0.9454545454545454 \n",
      "Avg loss:  0.4415896385908127\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.452664  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4395766854286194\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.382427  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4319872111082077\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.435003  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4383780360221863\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.359490  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4323766827583313\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.385532  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.42640164494514465\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.445314  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.43393684923648834\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.503463  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4240926504135132\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.409921  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4244198799133301\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.466039  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.42096981406211853\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.379980  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.4142480939626694\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.373435  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.413144513964653\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.391816  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.41892118752002716\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.388965  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.4187595993280411\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.469292  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.40705734491348267\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.380566  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.4027184098958969\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.530410  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.39747659862041473\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.422603  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.40125399827957153\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.484869  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3949388563632965\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.420106  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.4024890959262848\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.421284  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3968221843242645\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.385459  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3924335092306137\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.419397  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3878420442342758\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.372591  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.39213475584983826\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.347058  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.39143510162830353\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.369552  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.39196696877479553\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.382970  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3831438422203064\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.379577  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.38625024259090424\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.370721  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.38039426505565643\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.388306  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.378239169716835\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.353475  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3735668361186981\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.299415  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36949141323566437\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.342999  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3671601563692093\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.386429  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36774154007434845\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.376606  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36500027775764465\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.363375  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3585900515317917\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.365820  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36062362790107727\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.376647  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36156313121318817\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.330359  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.36022454500198364\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.377917  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3602270185947418\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.381938  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.35486625134944916\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.389265  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.35280196368694305\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.307683  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.35093478858470917\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.334871  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3517136722803116\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.335487  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3501499146223068\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.294787  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.35059110820293427\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.349348  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3501214236021042\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.400238  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3422633409500122\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.339838  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.33720798790454865\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.358319  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.345711424946785\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.317949  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3347766101360321\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.349039  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.34164124727249146\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.332098  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.33191055059432983\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.340687  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.34024183452129364\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.354420  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.33580391108989716\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.371747  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.33032625913619995\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.351610  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3311666399240494\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.357823  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.33006006479263306\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.379961  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3274689316749573\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.323187  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.32117460668087006\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.303864  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.31990180909633636\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.309182  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3215287923812866\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.299234  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3279755264520645\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.330564  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.31936852633953094\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.348887  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30959659814834595\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.327074  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.31636983156204224\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.293924  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3177642822265625\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.308883  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3132968097925186\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.300238  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.3111286461353302\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.308546  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.308880940079689\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.298016  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30922093987464905\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.368519  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30581966042518616\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.300943  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30938032269477844\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.298531  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30722250044345856\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.312091  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.298385813832283\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.348276  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2988433241844177\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.295250  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.29992949962615967\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279763  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.30421167612075806\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.330720  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.30560576915740967\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.307681  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.29809562861919403\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.256119  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.29739437997341156\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.293589  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.298363596200943\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.274912  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.28837448358535767\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.271091  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2975742220878601\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.282761  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.29429319500923157\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.289819  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.287604957818985\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.349566  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.28988006711006165\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.277739  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2877286225557327\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279385  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2838364988565445\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.244658  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2876874804496765\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.305398  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.28548550605773926\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.305672  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2870328724384308\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.245820  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.27755241096019745\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.294215  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2791346609592438\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.227163  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.27942076325416565\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.280159  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.28000085055828094\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.294748  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.27865205705165863\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.263413  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.27798929810523987\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.317949  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.27264972031116486\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.294625  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2739308327436447\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.300330  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2716970145702362\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.233856  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2745722234249115\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.290016  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2679208517074585\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.269760  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26722554862499237\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.266027  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26888445019721985\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.267074  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26795458793640137\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.246247  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26880739629268646\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.250704  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26565657556056976\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.264440  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2634374052286148\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.260958  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.26765701174736023\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.316195  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2639474868774414\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.270706  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2602279633283615\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.223172  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.25737373530864716\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.226062  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2570265382528305\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.234549  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.26023106276988983\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279169  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2516561821103096\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.272194  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2461388260126114\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.275204  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.25211475044488907\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.255347  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.25154194980859756\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.255582  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.24699772894382477\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.241092  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.25241364538669586\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.263812  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2539561688899994\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.196827  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2485002502799034\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.255608  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.25241465866565704\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.278303  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.25038208812475204\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279788  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2413763552904129\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.214714  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2471167966723442\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.240872  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.23886384069919586\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.233188  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.24060878157615662\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211549  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.24697357416152954\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.239671  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.24658751487731934\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.249187  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.24171120673418045\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.275060  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.24147272109985352\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.222036  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.23564354330301285\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.271647  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.2425365298986435\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.193369  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.23726166039705276\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.253491  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.23686432093381882\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.253804  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2392694652080536\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.278612  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.23926174640655518\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.224098  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.24350044876337051\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.239491  [  928/ 1760]Test: \n",
      "Accuracy:  0.9636363636363636 \n",
      "Avg loss:  0.2317894622683525\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.235039  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.23482546210289001\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.238572  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.23348716646432877\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.196372  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.23088958114385605\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.266291  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.231358602643013\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.279223  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.23634788393974304\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.249630  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22649021446704865\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.231226  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.2300463765859604\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.182295  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.22713017463684082\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.222044  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22896169871091843\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.272400  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21929842233657837\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188674  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22640922665596008\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.184332  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22565966099500656\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169844  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.22830039262771606\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.227313  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22867343574762344\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.206888  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.2312132567167282\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.198971  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22406704723834991\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.248203  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.22084075957536697\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.203090  [  928/ 1760]Test: \n",
      "Accuracy:  0.95 \n",
      "Avg loss:  0.22392957657575607\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.218036  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.22367334365844727\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.229813  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.2148563712835312\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.218482  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21512237936258316\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.180079  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21434006839990616\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.221419  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.21696870774030685\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.229486  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21727559715509415\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.248709  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21329840272665024\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188006  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21866808831691742\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.222434  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21148868650197983\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.246977  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2082677260041237\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.210018  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21154222637414932\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.150553  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21524199098348618\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.266804  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2158065065741539\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.197075  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20677798241376877\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.232594  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20900516211986542\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.210903  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.21129560470581055\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.208216  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.21230023354291916\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169220  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20732062309980392\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.239559  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20909098535776138\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.218031  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20561355352401733\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.191867  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.21403223276138306\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.250947  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.2077290043234825\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.183743  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20357134193181992\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.186784  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20383498072624207\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211362  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.2021176442503929\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.225686  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20299351960420609\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.173512  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20187996327877045\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.191407  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20430754870176315\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.217287  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19765466451644897\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.192377  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.19757989794015884\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.199221  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20030631124973297\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.209532  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20699907094240189\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.191500  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19699310511350632\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.194458  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19944359362125397\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.171831  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.206480972468853\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187580  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20023372769355774\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.170747  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19228355586528778\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.186791  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.200612410902977\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.171097  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.20441240072250366\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.168109  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19820859283208847\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.157684  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19940285384655\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.208254  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1990829035639763\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.182028  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19482114166021347\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.179707  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19708577543497086\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.162461  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19349581003189087\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211961  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.19457650929689407\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.164786  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.18984097242355347\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.237318  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.19296514242887497\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.146153  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1942039132118225\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.177062  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19435081630945206\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.202184  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18949603289365768\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.193932  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19283746182918549\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188266  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18934989720582962\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.191560  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1842433139681816\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.203452  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1844475269317627\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.214595  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18463358283042908\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.191031  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19310306757688522\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.159993  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18840937316417694\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.180420  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18937062472105026\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.153768  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.19503296166658401\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187298  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18471290171146393\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.180170  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18616440147161484\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.179737  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1880863904953003\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.204546  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1823272407054901\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.141710  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18437212705612183\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.237388  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17862501740455627\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.142129  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17786537110805511\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.144239  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18107833713293076\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169218  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1767100989818573\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.154842  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18025440722703934\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.211684  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1784287393093109\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.151822  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.18231402337551117\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.193947  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17897213250398636\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.172128  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17836487293243408\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.188900  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1810942068696022\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.171399  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17933199554681778\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.181219  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1834310069680214\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.166573  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17676838487386703\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.158188  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17662101984024048\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.177479  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17852485924959183\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.187441  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.17359289526939392\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.189780  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17430367320775986\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.169584  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.16882917284965515\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.175578  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17796875536441803\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.194875  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.175770103931427\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.203318  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17797520756721497\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.172503  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17583096772432327\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.163942  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.16899745911359787\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.135356  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1743909791111946\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.174328  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1714620739221573\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.177825  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17395515739917755\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.181347  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1716468706727028\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.140810  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.16961722820997238\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.185478  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17109351605176926\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.155405  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.1734921932220459\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.163274  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17168617993593216\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.160201  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17405807226896286\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.141586  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.16889795660972595\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.192099  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17315595597028732\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.201307  [  928/ 1760]Test: \n",
      "Accuracy:  0.9590909090909091 \n",
      "Avg loss:  0.162976436316967\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.157251  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.16910458356142044\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.184625  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.17222212255001068\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.164697  [  928/ 1760]Test: \n",
      "Accuracy:  0.9545454545454546 \n",
      "Avg loss:  0.16855096817016602\n",
      "\n",
      "\n",
      "\n",
      "Validation Data: \n",
      "Test: \n",
      "Accuracy:  0.9818181818181818 \n",
      "Avg loss:  0.15059573203325272\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    print(\"\")\n",
    "    train_loop(train_data_loader)\n",
    "    test_loop(test_data_loader)\n",
    "\n",
    "print(\"\\n\\n\\nValidation Data: \")\n",
    "test_loop(validation_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:09:59.799329Z",
     "start_time": "2024-05-04T09:08:57.362065Z"
    }
   },
   "id": "d2e4f33c43d0c1a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
