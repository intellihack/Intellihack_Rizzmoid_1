{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:41.676458Z",
     "start_time": "2024-05-04T08:45:40.619842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((1980, 12), (220, 12))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Crop_Dataset.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, train_size=0.9)\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(data['Label_Encoded'].unique())\n",
    "n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:41.683047Z",
     "start_time": "2024-05-04T08:45:41.677252Z"
    }
   },
   "id": "134db0c50579d075"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"mps\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.680744Z",
     "start_time": "2024-05-04T08:45:41.680201Z"
    }
   },
   "id": "25c98d5511cd1168"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.inputs = data.iloc[:, 0:-2].values.astype('float32')\n",
    "        \n",
    "        # for i in range(self.inputs.shape[1]):\n",
    "        #     self.inputs[:, i] = normalize(torch.tensor(self.inputs[:, i].reshape(-1, 1), device=device), dim=0).reshape(-1)\n",
    "        # do min max normalization\n",
    "        for i in range(self.inputs.shape[1]):\n",
    "            max_val = self.inputs[:, i].max()\n",
    "            min_val = self.inputs[:, i].min()\n",
    "            self.inputs[:, i] = (self.inputs[:, i] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        self.outputs = data.iloc[:, -1].values.astype('int')\n",
    "        \n",
    "        self.inputs = torch.tensor(self.inputs, device=device)\n",
    "        self.outputs = torch.tensor(self.outputs, device=device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.683721Z",
     "start_time": "2024-05-04T08:45:42.682096Z"
    }
   },
   "id": "6f491ad7458c9537"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(CustomDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(CustomDataset(test_data), batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.743413Z",
     "start_time": "2024-05-04T08:45:42.685256Z"
    }
   },
   "id": "97345e2e0fba23c6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([128, 10])\n",
      "Shape of y:  torch.Size([128]) torch.int64\n",
      "Sample X:  tensor([0.6786, 0.5500, 0.2150, 0.5328, 0.8055, 0.3448, 0.2607, 0.5652, 0.5319,\n",
      "        0.5614], device='mps:0')\n",
      "Sample y:  tensor(10, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# print shapes and samples from the dataset\n",
    "for X, y in train_data_loader:\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    print(\"Sample X: \", X[0])\n",
    "    print(\"Sample y: \", y[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.920720Z",
     "start_time": "2024-05-04T08:45:42.743721Z"
    }
   },
   "id": "5545db8d69fbc4fa"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 22),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.921396Z",
     "start_time": "2024-05-04T08:45:42.903882Z"
    }
   },
   "id": "c232c3144a1df0d6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=22, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.921873Z",
     "start_time": "2024-05-04T08:45:42.907454Z"
    }
   },
   "id": "c272fb94daa41e97"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([10], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# testing predictions\n",
    "\n",
    "_X = torch.rand(1, 10, device=device)\n",
    "logits = model(_X)\n",
    "predicted_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = predicted_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.977761Z",
     "start_time": "2024-05-04T08:45:42.914614Z"
    }
   },
   "id": "100378c7ad3a6a73"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:42.981024Z",
     "start_time": "2024-05-04T08:45:42.976821Z"
    }
   },
   "id": "4993b936e24ca0f3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlakshith\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/lakshithnishshanke/Developer/Intellihack/Intellihack_Rizzmoid_1/wandb/run-20240504_141544-inhddp1w</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='http://localhost:8080/lakshith/Intellihack_1/runs/inhddp1w' target=\"_blank\">elegant-droid-17</a></strong> to <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='http://localhost:8080/lakshith/Intellihack_1' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='http://localhost:8080/lakshith/Intellihack_1/runs/inhddp1w' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_1/runs/inhddp1w</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='http://localhost:8080/lakshith/Intellihack_1/runs/inhddp1w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x17d0dc0a0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "configs = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"ANN\",\n",
    "    \"dataset\": \"Crop\",\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Intellihack_1\",\n",
    "    config=configs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:46.230065Z",
     "start_time": "2024-05-04T08:45:42.979194Z"
    }
   },
   "id": "3f08bf8faaddb863"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_loop(dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, current = loss.item(), batch * batch_size + len(X)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Loss\": loss\n",
    "        })\n",
    "        print(f\"\\rloss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:46.233986Z",
     "start_time": "2024-05-04T08:45:46.211669Z"
    }
   },
   "id": "263db61f89b14c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test_loop(dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(\"\\n\",{\"test_loss\": test_loss, \"test_acc\": correct})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:46.322242Z",
     "start_time": "2024-05-04T08:45:46.216321Z"
    }
   },
   "id": "7a025d958375368f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T08:45:46.322689Z",
     "start_time": "2024-05-04T08:45:46.219009Z"
    }
   },
   "id": "919104987103baeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.080860  [ 1980/ 1980]\n",
      " {'test_loss': 3.0796903371810913, 'test_acc': 0.07727272727272727}\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.078977  [ 1980/ 1980]\n",
      " {'test_loss': 3.0704257488250732, 'test_acc': 0.10454545454545454}\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.064404  [ 1980/ 1980]\n",
      " {'test_loss': 3.0631799697875977, 'test_acc': 0.10909090909090909}\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.040269  [ 1980/ 1980]\n",
      " {'test_loss': 3.0546863079071045, 'test_acc': 0.10909090909090909}\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.037268  [ 1980/ 1980]\n",
      " {'test_loss': 3.0452760457992554, 'test_acc': 0.11818181818181818}\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.040856  [ 1980/ 1980]\n",
      " {'test_loss': 3.0387332439422607, 'test_acc': 0.14545454545454545}\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.040850  [ 1980/ 1980]\n",
      " {'test_loss': 3.029783844947815, 'test_acc': 0.14545454545454545}\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.999926  [ 1980/ 1980]\n",
      " {'test_loss': 3.0228010416030884, 'test_acc': 0.15}\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "\n",
      "loss: 3.005121  [ 1980/ 1980]\n",
      " {'test_loss': 3.014410614967346, 'test_acc': 0.15454545454545454}\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.009864  [ 1980/ 1980]\n",
      " {'test_loss': 3.00442898273468, 'test_acc': 0.16818181818181818}\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.989879  [ 1980/ 1980]\n",
      " {'test_loss': 2.9927470684051514, 'test_acc': 0.17272727272727273}\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.980236  [ 1980/ 1980]\n",
      " {'test_loss': 2.987212061882019, 'test_acc': 0.18636363636363637}\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.973266  [ 1980/ 1980]\n",
      " {'test_loss': 2.9816166162490845, 'test_acc': 0.19090909090909092}\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.979085  [ 1980/ 1980]\n",
      " {'test_loss': 2.965813398361206, 'test_acc': 0.19545454545454546}\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.964369  [ 1980/ 1980]\n",
      " {'test_loss': 2.9605871438980103, 'test_acc': 0.21818181818181817}\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.945499  [ 1980/ 1980]\n",
      " {'test_loss': 2.947757601737976, 'test_acc': 0.22272727272727272}\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.904451  [ 1980/ 1980]\n",
      " {'test_loss': 2.936471104621887, 'test_acc': 0.21363636363636362}\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.916760  [ 1980/ 1980]\n",
      " {'test_loss': 2.927617311477661, 'test_acc': 0.22272727272727272}\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.919952  [ 1980/ 1980]\n",
      " {'test_loss': 2.9192296266555786, 'test_acc': 0.2318181818181818}\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.842094  [ 1980/ 1980]\n",
      " {'test_loss': 2.9046993255615234, 'test_acc': 0.2636363636363636}\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.880645  [ 1980/ 1980]\n",
      " {'test_loss': 2.89724063873291, 'test_acc': 0.2681818181818182}\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.924264  [ 1980/ 1980]\n",
      " {'test_loss': 2.8801047801971436, 'test_acc': 0.2818181818181818}\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.891850  [ 1980/ 1980]\n",
      " {'test_loss': 2.8674519062042236, 'test_acc': 0.2909090909090909}\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.829348  [ 1980/ 1980]\n",
      " {'test_loss': 2.862061619758606, 'test_acc': 0.30454545454545456}\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.802231  [ 1980/ 1980]\n",
      " {'test_loss': 2.8410836458206177, 'test_acc': 0.3090909090909091}\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.777624  [ 1980/ 1980]\n",
      " {'test_loss': 2.8263763189315796, 'test_acc': 0.3181818181818182}\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.796884  [ 1980/ 1980]\n",
      " {'test_loss': 2.8221322298049927, 'test_acc': 0.33636363636363636}\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.863565  [ 1980/ 1980]\n",
      " {'test_loss': 2.8036298751831055, 'test_acc': 0.36363636363636365}\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.866457  [ 1980/ 1980]\n",
      " {'test_loss': 2.7826870679855347, 'test_acc': 0.38181818181818183}\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.757023  [ 1980/ 1980]\n",
      " {'test_loss': 2.764077305793762, 'test_acc': 0.39545454545454545}\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.688921  [ 1980/ 1980]\n",
      " {'test_loss': 2.7500784397125244, 'test_acc': 0.41818181818181815}\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.749281  [ 1980/ 1980]\n",
      " {'test_loss': 2.7396832704544067, 'test_acc': 0.42727272727272725}\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.739414  [ 1980/ 1980]\n",
      " {'test_loss': 2.722712993621826, 'test_acc': 0.4681818181818182}\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.764276  [ 1980/ 1980]\n",
      " {'test_loss': 2.7035346031188965, 'test_acc': 0.4818181818181818}\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.777148  [ 1980/ 1980]\n",
      " {'test_loss': 2.6867239475250244, 'test_acc': 0.5136363636363637}\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.548243  [ 1980/ 1980]\n",
      " {'test_loss': 2.6659070253372192, 'test_acc': 0.5181818181818182}\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.654817  [ 1980/ 1980]\n",
      " {'test_loss': 2.6516072750091553, 'test_acc': 0.5181818181818182}\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.638705  [ 1980/ 1980]\n",
      " {'test_loss': 2.6239233016967773, 'test_acc': 0.5272727272727272}\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.486007  [ 1980/ 1980]\n",
      " {'test_loss': 2.6136521100997925, 'test_acc': 0.5227272727272727}\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.663379  [ 1980/ 1980]\n",
      " {'test_loss': 2.5939509868621826, 'test_acc': 0.5181818181818182}\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.597877  [ 1980/ 1980]\n",
      " {'test_loss': 2.570371985435486, 'test_acc': 0.509090909090909}\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.593329  [ 1980/ 1980]\n",
      " {'test_loss': 2.5539894104003906, 'test_acc': 0.5136363636363637}\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.549063  [ 1980/ 1980]\n",
      " {'test_loss': 2.526294231414795, 'test_acc': 0.5181818181818182}\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.581124  [ 1980/ 1980]\n",
      " {'test_loss': 2.5100427865982056, 'test_acc': 0.5272727272727272}\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.533783  [ 1980/ 1980]\n",
      " {'test_loss': 2.5020514726638794, 'test_acc': 0.5272727272727272}\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.580912  [ 1980/ 1980]\n",
      " {'test_loss': 2.4803637266159058, 'test_acc': 0.5318181818181819}\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.388295  [ 1980/ 1980]\n",
      " {'test_loss': 2.4539233446121216, 'test_acc': 0.5318181818181819}\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.401018  [ 1980/ 1980]\n",
      " {'test_loss': 2.4253225326538086, 'test_acc': 0.5272727272727272}\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.455001  [ 1980/ 1980]\n",
      " {'test_loss': 2.416849732398987, 'test_acc': 0.5409090909090909}\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.351636  [ 1980/ 1980]\n",
      " {'test_loss': 2.3874446153640747, 'test_acc': 0.5590909090909091}\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.424584  [ 1980/ 1980]\n",
      " {'test_loss': 2.373782515525818, 'test_acc': 0.5590909090909091}\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.409605  [ 1980/ 1980]\n",
      " {'test_loss': 2.3465205430984497, 'test_acc': 0.5636363636363636}\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.287278  [ 1980/ 1980]\n",
      " {'test_loss': 2.311701536178589, 'test_acc': 0.6}\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.288338  [ 1980/ 1980]\n",
      " {'test_loss': 2.2900540828704834, 'test_acc': 0.5772727272727273}\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.239611  [ 1980/ 1980]\n",
      " {'test_loss': 2.275856614112854, 'test_acc': 0.5818181818181818}\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.309142  [ 1980/ 1980]\n",
      " {'test_loss': 2.249645948410034, 'test_acc': 0.6045454545454545}\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.354734  [ 1980/ 1980]\n",
      " {'test_loss': 2.2266188859939575, 'test_acc': 0.6272727272727273}\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.292745  [ 1980/ 1980]\n",
      " {'test_loss': 2.1984928846359253, 'test_acc': 0.6318181818181818}\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.290377  [ 1980/ 1980]\n",
      " {'test_loss': 2.16808819770813, 'test_acc': 0.6409090909090909}\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.229031  [ 1980/ 1980]\n",
      " {'test_loss': 2.1601955890655518, 'test_acc': 0.6409090909090909}\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.186906  [ 1980/ 1980]\n",
      " {'test_loss': 2.129816174507141, 'test_acc': 0.6454545454545455}\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.200237  [ 1980/ 1980]\n",
      " {'test_loss': 2.091792583465576, 'test_acc': 0.65}\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.149693  [ 1980/ 1980]\n",
      " {'test_loss': 2.0713143348693848, 'test_acc': 0.6727272727272727}\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.076149  [ 1980/ 1980]\n",
      " {'test_loss': 2.054512858390808, 'test_acc': 0.6727272727272727}\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.140263  [ 1980/ 1980]\n",
      " {'test_loss': 2.01148784160614, 'test_acc': 0.6727272727272727}\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.060438  [ 1980/ 1980]\n",
      " {'test_loss': 2.0022411346435547, 'test_acc': 0.6863636363636364}\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.038275  [ 1980/ 1980]\n",
      " {'test_loss': 1.9778196811676025, 'test_acc': 0.6863636363636364}\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.967193  [ 1980/ 1980]\n",
      " {'test_loss': 1.9390472769737244, 'test_acc': 0.6954545454545454}\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "\n",
      "loss: 2.005607  [ 1980/ 1980]\n",
      " {'test_loss': 1.9152793884277344, 'test_acc': 0.6954545454545454}\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.905838  [ 1980/ 1980]\n",
      " {'test_loss': 1.8918826580047607, 'test_acc': 0.6954545454545454}\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.032363  [ 1980/ 1980]\n",
      " {'test_loss': 1.8764832019805908, 'test_acc': 0.7045454545454546}\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.818559  [ 1980/ 1980]\n",
      " {'test_loss': 1.834606945514679, 'test_acc': 0.7136363636363636}\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.899509  [ 1980/ 1980]\n",
      " {'test_loss': 1.8185794353485107, 'test_acc': 0.7181818181818181}\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.777475  [ 1980/ 1980]\n",
      " {'test_loss': 1.7957571148872375, 'test_acc': 0.7181818181818181}\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.711557  [ 1980/ 1980]\n",
      " {'test_loss': 1.767565369606018, 'test_acc': 0.7227272727272728}\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.781652  [ 1980/ 1980]\n",
      " {'test_loss': 1.7483885288238525, 'test_acc': 0.7227272727272728}\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.749515  [ 1980/ 1980]\n",
      " {'test_loss': 1.715328574180603, 'test_acc': 0.7272727272727273}\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.781244  [ 1980/ 1980]\n",
      " {'test_loss': 1.6892492175102234, 'test_acc': 0.7318181818181818}\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.652339  [ 1980/ 1980]\n",
      " {'test_loss': 1.6733774542808533, 'test_acc': 0.7318181818181818}\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.765276  [ 1980/ 1980]\n",
      " {'test_loss': 1.6412402987480164, 'test_acc': 0.7454545454545455}\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.758532  [ 1980/ 1980]\n",
      " {'test_loss': 1.628234088420868, 'test_acc': 0.75}\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.721341  [ 1980/ 1980]\n",
      " {'test_loss': 1.592490315437317, 'test_acc': 0.7636363636363637}\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.552939  [ 1980/ 1980]\n",
      " {'test_loss': 1.5669488310813904, 'test_acc': 0.7636363636363637}\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.659577  [ 1980/ 1980]\n",
      " {'test_loss': 1.5474310517311096, 'test_acc': 0.7727272727272727}\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.578062  [ 1980/ 1980]\n",
      " {'test_loss': 1.521741509437561, 'test_acc': 0.7727272727272727}\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.457616  [ 1980/ 1980]\n",
      " {'test_loss': 1.5077083110809326, 'test_acc': 0.7772727272727272}\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.615913  [ 1980/ 1980]\n",
      " {'test_loss': 1.4864543676376343, 'test_acc': 0.7818181818181819}\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.474005  [ 1980/ 1980]\n",
      " {'test_loss': 1.4679769277572632, 'test_acc': 0.7909090909090909}\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.508683  [ 1980/ 1980]\n",
      " {'test_loss': 1.4337024092674255, 'test_acc': 0.7909090909090909}\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.450268  [ 1980/ 1980]\n",
      " {'test_loss': 1.4244100451469421, 'test_acc': 0.8}\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.548275  [ 1980/ 1980]\n",
      " {'test_loss': 1.4164502620697021, 'test_acc': 0.7954545454545454}\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.450494  [ 1980/ 1980]\n",
      " {'test_loss': 1.392784297466278, 'test_acc': 0.8090909090909091}\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.477212  [ 1980/ 1980]\n",
      " {'test_loss': 1.3668485879898071, 'test_acc': 0.8181818181818182}\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.344512  [ 1980/ 1980]\n",
      " {'test_loss': 1.356500506401062, 'test_acc': 0.8136363636363636}\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.392651  [ 1980/ 1980]\n",
      " {'test_loss': 1.3249652981758118, 'test_acc': 0.8136363636363636}\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.361769  [ 1980/ 1980]\n",
      " {'test_loss': 1.317349135875702, 'test_acc': 0.8272727272727273}\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.292048  [ 1980/ 1980]\n",
      " {'test_loss': 1.2910154461860657, 'test_acc': 0.8318181818181818}\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.251627  [ 1980/ 1980]\n",
      " {'test_loss': 1.273658037185669, 'test_acc': 0.8363636363636363}\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.158897  [ 1980/ 1980]\n",
      " {'test_loss': 1.253713846206665, 'test_acc': 0.8454545454545455}\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.351302  [ 1980/ 1980]\n",
      " {'test_loss': 1.2295650243759155, 'test_acc': 0.85}\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.340140  [ 1980/ 1980]\n",
      " {'test_loss': 1.225808322429657, 'test_acc': 0.85}\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.229768  [ 1980/ 1980]\n",
      " {'test_loss': 1.212895393371582, 'test_acc': 0.8590909090909091}\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.226155  [ 1980/ 1980]\n",
      " {'test_loss': 1.1881428956985474, 'test_acc': 0.8681818181818182}\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.246262  [ 1980/ 1980]\n",
      " {'test_loss': 1.1713787317276, 'test_acc': 0.8590909090909091}\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.240698  [ 1980/ 1980]\n",
      " {'test_loss': 1.1616448163986206, 'test_acc': 0.8681818181818182}\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.164498  [ 1980/ 1980]\n",
      " {'test_loss': 1.1416457891464233, 'test_acc': 0.8545454545454545}\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.136655  [ 1980/ 1980]\n",
      " {'test_loss': 1.1377264261245728, 'test_acc': 0.8681818181818182}\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.106430  [ 1980/ 1980]\n",
      " {'test_loss': 1.1045581698417664, 'test_acc': 0.8727272727272727}\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.215651  [ 1980/ 1980]\n",
      " {'test_loss': 1.1005176305770874, 'test_acc': 0.8772727272727273}\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.116198  [ 1980/ 1980]\n",
      " {'test_loss': 1.0851913094520569, 'test_acc': 0.8818181818181818}\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.128613  [ 1980/ 1980]\n",
      " {'test_loss': 1.070724606513977, 'test_acc': 0.8954545454545455}\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.124456  [ 1980/ 1980]\n",
      " {'test_loss': 1.0608819723129272, 'test_acc': 0.8863636363636364}\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.074749  [ 1980/ 1980]\n",
      " {'test_loss': 1.046420931816101, 'test_acc': 0.8954545454545455}\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.194208  [ 1980/ 1980]\n",
      " {'test_loss': 1.023468166589737, 'test_acc': 0.9}\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.996302  [ 1980/ 1980]\n",
      " {'test_loss': 1.0185886025428772, 'test_acc': 0.8954545454545455}\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.031886  [ 1980/ 1980]\n",
      " {'test_loss': 0.9880494773387909, 'test_acc': 0.8909090909090909}\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.013380  [ 1980/ 1980]\n",
      " {'test_loss': 0.9902251958847046, 'test_acc': 0.8772727272727273}\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.081483  [ 1980/ 1980]\n",
      " {'test_loss': 0.9815402030944824, 'test_acc': 0.9}\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.023055  [ 1980/ 1980]\n",
      " {'test_loss': 0.9699528217315674, 'test_acc': 0.8909090909090909}\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.026059  [ 1980/ 1980]\n",
      " {'test_loss': 0.9519808292388916, 'test_acc': 0.8909090909090909}\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.893678  [ 1980/ 1980]\n",
      " {'test_loss': 0.9492098093032837, 'test_acc': 0.8909090909090909}\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.932161  [ 1980/ 1980]\n",
      " {'test_loss': 0.9383770823478699, 'test_acc': 0.9045454545454545}\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.955281  [ 1980/ 1980]\n",
      " {'test_loss': 0.9242247045040131, 'test_acc': 0.9136363636363637}\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.907974  [ 1980/ 1980]\n",
      " {'test_loss': 0.9144090712070465, 'test_acc': 0.9045454545454545}\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "\n",
      "loss: 1.044224  [ 1980/ 1980]\n",
      " {'test_loss': 0.8955383598804474, 'test_acc': 0.9136363636363637}\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.972405  [ 1980/ 1980]\n",
      " {'test_loss': 0.9017458260059357, 'test_acc': 0.9272727272727272}\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 1.010700  [ 1980/ 1980]\n",
      " {'test_loss': 0.8833605051040649, 'test_acc': 0.9272727272727272}\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.938524  [ 1980/ 1980]\n",
      " {'test_loss': 0.8780763447284698, 'test_acc': 0.9227272727272727}\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.783991  [ 1980/ 1980]\n",
      " {'test_loss': 0.8636512458324432, 'test_acc': 0.9272727272727272}\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.870416  [ 1980/ 1980]\n",
      " {'test_loss': 0.8483537137508392, 'test_acc': 0.9409090909090909}\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.930142  [ 1980/ 1980]\n",
      " {'test_loss': 0.8426760733127594, 'test_acc': 0.9409090909090909}\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.818909  [ 1980/ 1980]\n",
      " {'test_loss': 0.8235593140125275, 'test_acc': 0.9318181818181818}\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.779030  [ 1980/ 1980]\n",
      " {'test_loss': 0.8276685178279877, 'test_acc': 0.9318181818181818}\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.767578  [ 1980/ 1980]\n",
      " {'test_loss': 0.8154620230197906, 'test_acc': 0.9318181818181818}\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.858332  [ 1980/ 1980]\n",
      " {'test_loss': 0.8126928806304932, 'test_acc': 0.9363636363636364}\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.830639  [ 1980/ 1980]\n",
      " {'test_loss': 0.7858889102935791, 'test_acc': 0.9409090909090909}\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.789629  [ 1980/ 1980]\n",
      " {'test_loss': 0.7867707312107086, 'test_acc': 0.9454545454545454}\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.791525  [ 1980/ 1980]\n",
      " {'test_loss': 0.771165519952774, 'test_acc': 0.9409090909090909}\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.745045  [ 1980/ 1980]\n",
      " {'test_loss': 0.7708646357059479, 'test_acc': 0.9363636363636364}\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.770833  [ 1980/ 1980]\n",
      " {'test_loss': 0.7759423553943634, 'test_acc': 0.9454545454545454}\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.772827  [ 1980/ 1980]\n",
      " {'test_loss': 0.7575088143348694, 'test_acc': 0.9363636363636364}\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.794568  [ 1980/ 1980]\n",
      " {'test_loss': 0.744731068611145, 'test_acc': 0.9454545454545454}\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.740333  [ 1980/ 1980]\n",
      " {'test_loss': 0.7407362461090088, 'test_acc': 0.95}\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.788399  [ 1980/ 1980]\n",
      " {'test_loss': 0.7393642365932465, 'test_acc': 0.9545454545454546}\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.781673  [ 1980/ 1980]\n",
      " {'test_loss': 0.7186307609081268, 'test_acc': 0.95}\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.747630  [ 1980/ 1980]\n",
      " {'test_loss': 0.7220725119113922, 'test_acc': 0.9454545454545454}\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.765628  [ 1980/ 1980]\n",
      " {'test_loss': 0.7108863592147827, 'test_acc': 0.9363636363636364}\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.737398  [ 1980/ 1980]\n",
      " {'test_loss': 0.7082425653934479, 'test_acc': 0.9409090909090909}\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.664771  [ 1980/ 1980]\n",
      " {'test_loss': 0.6937993168830872, 'test_acc': 0.9454545454545454}\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.691173  [ 1980/ 1980]\n",
      " {'test_loss': 0.6858293414115906, 'test_acc': 0.95}\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.806056  [ 1980/ 1980]\n",
      " {'test_loss': 0.6850115954875946, 'test_acc': 0.95}\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.704069  [ 1980/ 1980]\n",
      " {'test_loss': 0.6766575276851654, 'test_acc': 0.9590909090909091}\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.744011  [ 1980/ 1980]\n",
      " {'test_loss': 0.6744561493396759, 'test_acc': 0.9409090909090909}\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.654381  [ 1980/ 1980]\n",
      " {'test_loss': 0.659282386302948, 'test_acc': 0.95}\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.643225  [ 1980/ 1980]\n",
      " {'test_loss': 0.6542536914348602, 'test_acc': 0.9454545454545454}\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.650014  [ 1980/ 1980]\n",
      " {'test_loss': 0.6463924646377563, 'test_acc': 0.9454545454545454}\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.727554  [ 1980/ 1980]\n",
      " {'test_loss': 0.6421536803245544, 'test_acc': 0.95}\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.668341  [ 1980/ 1980]\n",
      " {'test_loss': 0.633537083864212, 'test_acc': 0.9545454545454546}\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.671740  [ 1980/ 1980]\n",
      " {'test_loss': 0.6363179981708527, 'test_acc': 0.9545454545454546}\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.655950  [ 1980/ 1980]\n",
      " {'test_loss': 0.6254720985889435, 'test_acc': 0.9545454545454546}\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.597879  [ 1980/ 1980]\n",
      " {'test_loss': 0.6153734028339386, 'test_acc': 0.9545454545454546}\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.631256  [ 1980/ 1980]\n",
      " {'test_loss': 0.6137019395828247, 'test_acc': 0.9545454545454546}\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.607466  [ 1980/ 1980]\n",
      " {'test_loss': 0.6043977439403534, 'test_acc': 0.9590909090909091}\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.657510  [ 1980/ 1980]\n",
      " {'test_loss': 0.6083052158355713, 'test_acc': 0.9545454545454546}\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.607109  [ 1980/ 1980]\n",
      " {'test_loss': 0.5974024534225464, 'test_acc': 0.9545454545454546}\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.527649  [ 1980/ 1980]\n",
      " {'test_loss': 0.5865762233734131, 'test_acc': 0.9590909090909091}\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.633336  [ 1980/ 1980]\n",
      " {'test_loss': 0.588624119758606, 'test_acc': 0.9545454545454546}\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.682698  [ 1980/ 1980]\n",
      " {'test_loss': 0.58560511469841, 'test_acc': 0.9590909090909091}\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.605679  [ 1980/ 1980]\n",
      " {'test_loss': 0.5783214867115021, 'test_acc': 0.9636363636363636}\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.633568  [ 1980/ 1980]\n",
      " {'test_loss': 0.5801919996738434, 'test_acc': 0.9590909090909091}\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.651108  [ 1980/ 1980]\n",
      " {'test_loss': 0.568862110376358, 'test_acc': 0.9590909090909091}\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.543804  [ 1980/ 1980]\n",
      " {'test_loss': 0.5634164810180664, 'test_acc': 0.9545454545454546}\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.588273  [ 1980/ 1980]\n",
      " {'test_loss': 0.5586633086204529, 'test_acc': 0.9590909090909091}\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.586350  [ 1980/ 1980]\n",
      " {'test_loss': 0.5520632863044739, 'test_acc': 0.9636363636363636}\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.643368  [ 1980/ 1980]\n",
      " {'test_loss': 0.5518748164176941, 'test_acc': 0.9590909090909091}\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.558350  [ 1980/ 1980]\n",
      " {'test_loss': 0.5499071478843689, 'test_acc': 0.9590909090909091}\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.560042  [ 1980/ 1980]\n",
      " {'test_loss': 0.5302156955003738, 'test_acc': 0.9590909090909091}\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.629565  [ 1980/ 1980]\n",
      " {'test_loss': 0.5441890805959702, 'test_acc': 0.9545454545454546}\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.569790  [ 1980/ 1980]\n",
      " {'test_loss': 0.5296456813812256, 'test_acc': 0.9545454545454546}\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.584086  [ 1980/ 1980]\n",
      " {'test_loss': 0.5285396575927734, 'test_acc': 0.95}\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.621117  [ 1980/ 1980]\n",
      " {'test_loss': 0.5232115685939789, 'test_acc': 0.9545454545454546}\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.456173  [ 1980/ 1980]\n",
      " {'test_loss': 0.5167844295501709, 'test_acc': 0.9545454545454546}\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.484196  [ 1980/ 1980]\n",
      " {'test_loss': 0.5140957236289978, 'test_acc': 0.9545454545454546}\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.479007  [ 1980/ 1980]\n",
      " {'test_loss': 0.506601095199585, 'test_acc': 0.9590909090909091}\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.485787  [ 1980/ 1980]\n",
      " {'test_loss': 0.5006522238254547, 'test_acc': 0.9590909090909091}\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.533055  [ 1980/ 1980]\n",
      " {'test_loss': 0.4952891170978546, 'test_acc': 0.9590909090909091}\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.427568  [ 1980/ 1980]\n",
      " {'test_loss': 0.5023039430379868, 'test_acc': 0.9590909090909091}\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.578806  [ 1980/ 1980]\n",
      " {'test_loss': 0.49653109908103943, 'test_acc': 0.9590909090909091}\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.488411  [ 1980/ 1980]\n",
      " {'test_loss': 0.4897739440202713, 'test_acc': 0.9545454545454546}\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.508272  [ 1980/ 1980]\n",
      " {'test_loss': 0.47843754291534424, 'test_acc': 0.9590909090909091}\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.521486  [ 1980/ 1980]\n",
      " {'test_loss': 0.48422224819660187, 'test_acc': 0.9545454545454546}\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.503237  [ 1980/ 1980]\n",
      " {'test_loss': 0.47638003528118134, 'test_acc': 0.9545454545454546}\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.631851  [ 1980/ 1980]\n",
      " {'test_loss': 0.47594016790390015, 'test_acc': 0.9590909090909091}\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.506121  [ 1980/ 1980]\n",
      " {'test_loss': 0.4698319733142853, 'test_acc': 0.9590909090909091}\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.485687  [ 1980/ 1980]\n",
      " {'test_loss': 0.4764476418495178, 'test_acc': 0.9590909090909091}\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.506003  [ 1980/ 1980]\n",
      " {'test_loss': 0.4616067111492157, 'test_acc': 0.95}\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.454191  [ 1980/ 1980]\n",
      " {'test_loss': 0.45886455476284027, 'test_acc': 0.9545454545454546}\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.466879  [ 1980/ 1980]\n",
      " {'test_loss': 0.45854713022708893, 'test_acc': 0.9590909090909091}\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.533435  [ 1980/ 1980]\n",
      " {'test_loss': 0.4514341652393341, 'test_acc': 0.9590909090909091}\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.498270  [ 1980/ 1980]\n",
      " {'test_loss': 0.45678845047950745, 'test_acc': 0.9545454545454546}\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.465813  [ 1980/ 1980]\n",
      " {'test_loss': 0.4490988105535507, 'test_acc': 0.9590909090909091}\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.444575  [ 1980/ 1980]\n",
      " {'test_loss': 0.4439823627471924, 'test_acc': 0.9590909090909091}\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.438116  [ 1980/ 1980]\n",
      " {'test_loss': 0.43938906490802765, 'test_acc': 0.9590909090909091}\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.496710  [ 1980/ 1980]\n",
      " {'test_loss': 0.437102347612381, 'test_acc': 0.9636363636363636}\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.422394  [ 1980/ 1980]\n",
      " {'test_loss': 0.4345376044511795, 'test_acc': 0.9590909090909091}\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.464899  [ 1980/ 1980]\n",
      " {'test_loss': 0.4269541800022125, 'test_acc': 0.9590909090909091}\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.473901  [ 1980/ 1980]\n",
      " {'test_loss': 0.42772263288497925, 'test_acc': 0.9636363636363636}\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.416862  [ 1980/ 1980]\n",
      " {'test_loss': 0.42365066707134247, 'test_acc': 0.95}\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.388130  [ 1980/ 1980]\n",
      " {'test_loss': 0.4184425175189972, 'test_acc': 0.9590909090909091}\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.440510  [ 1980/ 1980]\n",
      " {'test_loss': 0.42001278698444366, 'test_acc': 0.9636363636363636}\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.423153  [ 1980/ 1980]\n",
      " {'test_loss': 0.413915753364563, 'test_acc': 0.9590909090909091}\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.459581  [ 1980/ 1980]\n",
      " {'test_loss': 0.4127430319786072, 'test_acc': 0.9545454545454546}\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.402471  [ 1980/ 1980]\n",
      " {'test_loss': 0.4117818772792816, 'test_acc': 0.95}\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.463564  [ 1980/ 1980]\n",
      " {'test_loss': 0.41176149249076843, 'test_acc': 0.9590909090909091}\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.383973  [ 1980/ 1980]\n",
      " {'test_loss': 0.4071844220161438, 'test_acc': 0.9590909090909091}\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.399571  [ 1980/ 1980]\n",
      " {'test_loss': 0.4007408618927002, 'test_acc': 0.9636363636363636}\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.376044  [ 1980/ 1980]\n",
      " {'test_loss': 0.4014560431241989, 'test_acc': 0.9636363636363636}\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.421168  [ 1980/ 1980]\n",
      " {'test_loss': 0.39499492943286896, 'test_acc': 0.9545454545454546}\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.373314  [ 1980/ 1980]\n",
      " {'test_loss': 0.3928370922803879, 'test_acc': 0.9590909090909091}\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.379836  [ 1980/ 1980]\n",
      " {'test_loss': 0.39027056097984314, 'test_acc': 0.9636363636363636}\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.483617  [ 1980/ 1980]\n",
      " {'test_loss': 0.38502752780914307, 'test_acc': 0.9681818181818181}\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.386607  [ 1980/ 1980]\n",
      " {'test_loss': 0.3872124254703522, 'test_acc': 0.9636363636363636}\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "\n",
      "loss: 0.396771  [  384/ 1980]"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    print(\"\")\n",
    "    train_loop(train_data_loader)\n",
    "    test_loop(test_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-04T08:45:46.225083Z"
    }
   },
   "id": "d2e4f33c43d0c1a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7407f43db66dadc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
