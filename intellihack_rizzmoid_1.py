# -*- coding: utf-8 -*-
"""Intellihack_Rizzmoid_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/133Ku2ao0cCI_I67GC2-8_1nHBMRfElP4

**Intellihack_Rizzmoid_1**

Introduction

Solution to the task was implemented using a Decision Tree classifier model. The model is designed to predict the type of crop from a list (wheat, barley, lettuce, spinach, cauliflower, brussels_sprouts, cabbage, beans, peas, turnips, carrots, beets, cherries, plums, raspberries, pears, blackcurrants, strawberries, apples, potatoes, rapeseed, tomatoes) based on various environmental factors such as Nitrogen, Potassium, Phosphurus levels, temperature, humidity, pH level, rainfall, Total nutrients, Temparature Humidity, Log Rainfall.
"""

# !pip install scikit-learn

"""Above command is used to install the scikit-learn library in Python if it's not already installed in your environment."""

from __future__ import print_function
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

df = pd.read_csv("Crop_Dataset.csv")

# remove null value records
columns_to_check = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'Total_Nutrients', 'Temperature_Humidity', 'Log_Rainfall', 'Label_Encoded']
df.dropna(subset=columns_to_check, inplace=True)

"""The soultion is implemented using scikit-learn (which is a free and open-source machine learning library) and libraries such as pandas, numpy, ...etc was used. The data set provided was imported to /content directory beforehand and is used in the code.

Any records with Null values are dropped from the data set to avoid any inaccuracies and errors
"""

feature_columns = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall', 'Total_Nutrients', 'Temperature_Humidity', 'Log_Rainfall']]
target = df['Label_Encoded']
labels = df['Label']
crop_types = df['Label'].unique().tolist()


acc = []
model = []


from sklearn.model_selection import train_test_split
dftrain, dfeval, y_train, y_eval = train_test_split(feature_columns,target,test_size = 0.2,random_state =2)


DecisionTree = DecisionTreeClassifier(criterion="entropy",random_state=2,max_depth=5)

DecisionTree.fit(dftrain,y_train)

predicted_values = DecisionTree.predict(dfeval)
x = metrics.accuracy_score(y_eval, predicted_values)
acc.append(x)
model.append('Decision Tree')
print("DecisionTrees's Accuracy is: ", x*100)

"""The feature columns (N, P, K, temperature, humidity, ph, rainfall, Total_Nutrients, Temperature_Humidity, Log_Rainfall) were selected as input features for the model.

The target variable was defined as Label_Encoded, representing the encoded labels for different crop types.

The dataset was split into training and evaluation sets using an 80-20 ratio.

A Decision Tree classifier was instantiated with parameters:

  - Criterion: "entropy"

  - Random State: 2

  - Maximum Depth: 5

The model was trained on the training dataset using the fit() function.

The trained model was used to predict crop types for the evaluation dataset.
"""

import joblib
joblib.dump(DecisionTree, 'DescisionTreeModel')

loadedModel = joblib.load('/content/DescisionTreeModel')

import warnings
warnings.filterwarnings('ignore')

N = 67
P = 51
K = 24
temperature = 23.50297882
humidity = 61.32026065
ph = 5.584171461
rainfall = 64.77791424
Total_Nutrients = 142
Temperature_Humidity = 1441.208787
Log_Rainfall = 4.186284132

data = np.array([[N,P, K, temperature, humidity, ph, rainfall, Total_Nutrients, Temperature_Humidity, Log_Rainfall]])

prediction = loadedModel.predict(data)
# print(prediction)
# print(crop_types)
print(crop_types[prediction[0]])

"""A joblib model (.joblib) was created from the trained model as DescisionTreeModel.

A prediction was made using the loaded DescisionTreeModel

For the above test, the variables of the 164th record in the Crop_Dataset.csv file was used and the model predicted that the most suitable crop type was barley which was accurate with the record details

**Challenges Faced**

- Choosing the appropriate model and hyperparameters required experimentation and evaluation.
- Selecting suitable evaluation metrics to assess model performance accurately was challenging.

**Future Improvements**

- Further experimentation with different hyperparameters could potentially improve model performance.

**Instructions to run Model**

The Model was coded in Google Collab. To run in Google Collab, import the Crop_dataset.csv to /content/directory and run the individual cells in order

T
"""